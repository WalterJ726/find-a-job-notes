## 操作系统

#### B+和b树

CPU太快，磁盘太慢，所以要有个中间的东西，叫做页

datapage的整数倍

IO瓶颈问题

#### 线程池

我们预先创建好一系列线程，就好比后宫佳丽三千，然后皇上（线程池中枢）来了兴致（收到任务），就去翻一个妃子（线程池中某个线程）的牌子。妃子（线程）解决完需求后，回到后宫（线程池），等待下一次召唤。

不用创建和销毁，而是回收利用，所有池式结构都可以看做是一种对资源调度的缓冲，这就是线程池的精髓。

当前这个版本的线程池是基于互斥锁和条件变量实现的。

预告（画饼）：无锁线程池后续也会手撕。

线程池总体上可以分为三大组件。

- 任务队列（存还没有执行的任务）
- 执行队列（可以看成就是线程池，存放着可以用来执行任务的线程）
- 线程池管理中枢（负责封装前两个类，任务的分发，线程池的创建，销毁，等等。对外提供统一的接口

https://zhuanlan.zhihu.com/p/543476115

有两个队列，如果线程池满了，就放到任务队列里面去

线程池就是不需要代码自己创建线程，而是直接获取线程池中的线程，用完再还回去。相比手工创建和运行，能够降低线程创建和销毁的开销、提高响应速度、提高线程的可管理性。当你提交一个任务时，线程池首先会去看核心线程数是否达到上限，如果没有那就新建一个核心线程用来执行任务，否则去检查阻塞队列，如果阻塞队列未满，则加入阻塞队列，否则检查总线程数是否达到阈值，如果没有达到阈值，就建立一个非核心线程用来执行任务，否则执行线程池饱和策略。 核心线程数由 corePoolSize 参数决定，阻塞队列必须实现 BlockingQueue 接口，非核心线程达到存活的最长时间就销毁，饱和策略有：抛出异常（默认）、抛弃任务、抛弃最旧（下一个要运行）的任务、在主线程中执行任务。 不同线程池区别在于核心线程数是否固定、阻塞队列的实现（如ArrayBlockingQueue、LinkedBlockedQueue、PriorityBlockingQueue、DelayQueue、SynchronousQueue）、非核心线程数的最长存活时间等等参数的限定。



#### 条件变量

C++条件变量（Condition Variable）是一种多线程编程中的同步机制，用于线程之间的协调和通信。条件变量用于在某些条件满足时通知等待线程进行操作，以避免线程的无效轮询，从而提高程序的效率。

条件变量通常与互斥锁（Mutex）一起使用，以确保在访问共享资源时的互斥性。当一个线程在等待条件变量时，它会释放它持有的互斥锁，这样其他线程就可以访问共享资源。当满足条件时，通知线程会重新获得互斥锁，继续执行操作。

在C++11之前，条件变量需要与特定的线程库一起使用，例如Windows线程库的“Condition Variables”或Linux线程库的“POSIX Threads”。但是，C++11引入了标准库中的条件变量，使得跨平台的多线程编程更加方便。

在C++标准库中，条件变量通常由std::condition_variable类表示，它提供了wait()、notify_one()和notify_all()等方法，可以用于等待和唤醒线程。使用条件变量需要遵循一些约定和规则，例如等待前必须持有互斥锁等，以确保正确的线程同步。

## 进程和线程的区别

**进程是最基本的资源分配单位，线程是CPU最基本的执行单位。这指的是进程会分配heap，global variables等。而线程只会分配栈等资源**

进程是操作系统资源分配的基本单位，它拥有独立的地址空间、堆栈、文件描述符和其他系统资源，同时也具有一定的独立性和并发性。操作系统通过进程的调度和管理来控制计算机资源的分配和使用，以满足不同进程的需求和优先级。

线程是否有自己的资源吗？ 有，会分配stack，stack pointer， program counter

两个进程是相互独立的，因为它们拥有各自独立的虚拟地址空间，互不干扰。每个进程拥有自己的代码段、数据段、堆栈等内存区域，可以独立地进行内存的读写操作，而且不会影响其他进程的内存。

此外，每个进程还拥有独立的文件描述符、进程ID、用户ID、组ID等资源，它们之间也是相互独立的。进程可以创建子进程，但是这些子进程也是相互独立的，除非它们之间进行了特殊的共享操作，如进程间通信（IPC）等。

虽然进程之间是相互独立的，但是它们可以通过进程间通信机制（如管道、消息队列、共享内存等）来实现数据的共享和协作，从而实现分布式计算、并发编程等功能。这些通信机制都是由操作系统提供的，它们允许不同进程之间进行数据交换和同步操作，从而提高系统的效率和可靠性。

1. 新建状态（New）：当线程对象被创建后，处于新建状态，此时尚未开始执行线程。
2. 就绪状态（Runnable）：当调用线程的 start() 方法后，线程会进入就绪状态，等待获取 CPU 时间片开始执行。就绪状态的线程可能会在等待锁、I/O 等操作时被阻塞。
3. 运行状态（Running）：线程获得了 CPU 时间片并开始执行，处于运行状态。此时线程可以访问 CPU 和内存等资源。
4. 阻塞状态（Blocked）：线程由于某些原因无法继续执行，进入阻塞状态，比如等待 I/O 完成或等待获取对象的锁等。阻塞状态的线程不会占用 CPU 时间片。
5. 等待状态（Waiting）：线程执行了某些操作后，需要等待其他线程或外部事件的通知才能继续执行，此时进入等待状态。如等待 join() 方法的返回或者调用了 wait() 方法等待其他线程的通知。
6. 计时等待状态（Timed Waiting）：和等待状态类似，不同的是等待一定时间后会自动返回，如 sleep() 方法等待指定时间后返回。
7. 终止状态（Terminated）：线程执行完任务后进入终止状态，线程执行完毕后自然结束，或者调用了 stop() 方法强制结束线程。

#### 进程之间通讯方式

本质都是同步机制

**1**）数据传输：一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几兆字节之间。

2）共享数据：多个进程想要操作共享数据，一个进程对共享数据的修改，别的进程应该立刻看到。

3）通知事件：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。

4）资源共享：多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。

5）进程控制：有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。

**1) 管道PIPES，通常指⽆名管道。（固定的进程）**

 ① 半双⼯的，具有固定的读端和写端；

 ② 只能⽤于具有亲属关系的进程之间的通信；

 ③ 可以看成是⼀种特殊的⽂件，对于它的读写也可以使⽤普通的read、write函数。

但是它不是普通的⽂件，并不 属于其他任何⽂件系统，只能⽤于内存中。

```cpp
c++Copy code#include <unistd.h>
#include <stdio.h>

int main()
{
    int fd[2];
    pid_t pid;
    char buf[256];

    if (pipe(fd) < 0) {
        //  **④ Int pipe(int fd[2]);当⼀个管道建⽴时，会创建两个⽂件⽂件描述符，要关闭管道只需将这两个⽂件描述符关闭 即可。** 
        perror("pipe error");
        return -1;
    }

    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        close(fd[0]);
        write(fd[1], "Hello, parent process!", 23);
        exit(0);
    } else {
        close(fd[1]);
        read(fd[0], buf, 256);
        printf("Received message: %s\n", buf);
    }
// 数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关通常是指父子进程关系。
    return 0;
}
```

**2) FiFO（有名管道） 无关的进程也可以， 可以重用**

① FIFO可以再⽆关的进程之间交换数据，与⽆名管道不同；

 ② FIFO有路径名与之相关联，它以⼀种特殊设备⽂件形式存在于⽂件系统中；备注了pathname

管道内容是存放在内存上的，磁盘上的仅仅只是标识，FIFO是文件，存在磁盘上

```cpp
#include <unistd.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <stdio.h>
#include <string.h>

#define FIFO_NAME "/tmp/my_fifo"

int main()
{
    int fd;
    char buf[256];

    if (mkfifo(FIFO_NAME, 0666) < 0) {
        // Int mkfifo(const char* pathname,mode_t mode); 
        perror("mkfifo error");
        return -1;
    }

    pid_t pid;
    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        fd = open(FIFO_NAME, O_WRONLY);
        write(fd, "Hello, parent process!", 23);
        close(fd);
        _exit(0);
    } else {
        fd = open(FIFO_NAME, O_RDONLY);
        read(fd, buf, 256);
        printf("Received message: %s\n", buf);
        close(fd);
    }

    unlink(FIFO_NAME);

    return 0;
}

```



**3) 消息队列** 

① 消息队列，是消息的连接表，存放在内核中。⼀个消息队列由⼀个标识符来标识；

 ② 消息队列是⾯向记录的，其中的消息具有特定的格式以及特定的优先级； 

③ 消息队列独⽴于发送与接收进程。进程终⽌时，消息队列及其内容并不会被删除； 

④ 消息队列可以实现消息的随机查询 

消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，**接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。**可以把消息看做一个记录，具有特定的格式以及特定的**优先级**。

进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列。

消息队列与命名管道的比较：

相同之处：与命名管道一样，消息队列进行通信的进程可以是不相关的进程，同时它们都是通过发送和接收的方式来传递数据的。在命名管道中，发送数据用write，接收数据用read，则在消息队列中，发送数据用msgsnd，接收数据用msgrcv。而且它们对每个数据都有一个最大长度的限制。

消息队列的优势在于：
1、消息队列也可以独立于发送和接收进程而存在，从而消除了在同步命名管道的打开和关闭时可能产生的困难。
2、同时通过发送消息还可以避免命名管道的同步和阻塞问题，不需要由进程自己来提供同步方法。
3、接收程序可以通过消息类型有选择地接收数据，而不是像命名管道中那样，只能默认地接收。

**4) 信号量**

信号量是一种同步机制，用于控制多个线程或进程对共享资源的访问。

是⼀个计数器，信号ᰁ⽤于实现进程间的互斥与同步，⽽不是⽤于存储进程间通信数据； 

② 信号ᰁ⽤于进程间同步，若要在进程间传递数据需要结合共享内存； ③ 信号ᰁ基于操作系统的PV操作，程序对信号ᰁ的操作都是原⼦操作；

1. 用于通知接收进程某个事件已经发生。

**5) 共享内存 （mmap）**

① 共享内存，指两个或多个进程共享⼀个给定的存储区；

 ② 共享内存是最快的⼀种进程通信⽅式，因为进程是直接对内存进⾏存取； 

③ 因为多个进程可以同时操作，所以需要进⾏同步； 

④ 信号量+共享内存通常结合在⼀起使⽤。

好处

```
省去了繁琐的I/O操作：使用mmap可以将文件或设备直接映射到内存中，进程可以直接访问内存中的数据，而不需要调用I/O操作（例如read()和write()等），避免了繁琐的数据拷贝和上下文切换操作。

避免了频繁的系统调用：使用mmap可以避免频繁的系统调用，减少了内核和用户态之间的上下文切换次数，提高了程序的性能和响应速度。

提高了文件访问效率：使用mmap可以利用操作系统的文件缓存机制，减少了文件的I/O次数，提高了文件的访问效率。

简化了代码实现：使用mmap可以简化代码实现，减少了对文件读写的操作，提高了程序的可读性和可维护性。

方便共享内存：使用mmap可以将同一个文件映射到不同的进程地址空间中，从而方便进程之间的数据共享。
```



坏处

```
内存管理的复杂性：使用mmap将文件映射到内存中后，需要对内存进行管理，包括申请和释放内存等操作，这需要更加复杂的内存管理机制，容易出现内存泄漏、内存冲突等问题。

对内存资源的消耗：使用mmap将文件映射到内存中后，会占用一部分内存资源，当需要处理大量的文件时，可能会导致内存资源不足，影响系统的稳定性。

可能会影响文件的一致性：如果多个进程同时对同一个文件进行mmap映射，由于内存映射是共享的，可能会导致文件的一致性问题，例如多个进程同时修改文件时，可能会导致文件内容不一致或者损坏。

可能会受到操作系统限制：操作系统可能会对mmap映射的大小、数量、映射文件的类型等进行限制，从而可能会限制程序的性能或者功能。
```



1. 管道

```cpp
c++Copy code#include <unistd.h>
#include <stdio.h>

int main()
{
    int fd[2];
    pid_t pid;
    char buf[256];

    if (pipe(fd) < 0) {
        perror("pipe error");
        return -1;
    }

    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        close(fd[0]);
        write(fd[1], "Hello, parent process!", 23);
        exit(0);
    } else {
        close(fd[1]);
        read(fd[0], buf, 256);
        printf("Received message: %s\n", buf);
    }

    return 0;
}
```

1. 共享内存

```cpp
#include <unistd.h>
#include <sys/mman.h>
#include <fcntl.h>
#include <stdio.h>
#include <string.h>

#define SHM_NAME "/my_shared_memory"
#define SHM_SIZE 4096

int main()
{
    int shm_fd;
    char *shm_ptr;

    shm_fd = shm_open(SHM_NAME, O_CREAT | O_RDWR, 0666);
    ftruncate(shm_fd, SHM_SIZE);
    shm_ptr = (char *) mmap(NULL, SHM_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, 0);

    pid_t pid;
    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        memcpy(shm_ptr, "Hello, parent process!", 23);
        exit(0);
    } else {
        sleep(1);
        printf("Received message: %s\n", shm_ptr);
    }

    munmap(shm_ptr, SHM_SIZE);
    close(shm_fd);
    shm_unlink(SHM_NAME);

    return 0;
}
```

1. 信号量

```cpp
#include <unistd.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/sem.h>
#include <stdio.h>
#include <stdlib.h>

#define KEY 1234

union semun {
    int val;
    struct semid_ds *buf;
    unsigned short *array;
    struct seminfo *__buf;
};

int main()
{
    int sem_id, pid;
    union semun sem_union;

    sem_id = semget(KEY, 1, 0666 | IPC_CREAT);
    sem_union.val = 1;
    semctl(sem_id, 0, SETVAL, sem_union);

    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        struct sembuf sem_op = {0, -1, 0};
        semop(sem_id, &sem_op, 1);
        printf("Child process acquire semaphore.\n");
        sleep(1);
        sem_op.sem_op = 1;
        semop(sem_id, &sem_op, 1);
        printf("Child process release semaphore.\n");
        exit(0);
    } else {
        sleep(2);
        printf("Parent process acquire semaphore.\n");
        struct sembuf sem_op = {0, -1, 0};
        semop(sem_id, &sem_op, 1);
        printf("Parent process release semaphore.\n");
    }

    semctl(sem_id, 0, IPC
```



**6） socket编程**

两个进程可以通过操作系统提供的进程间通信（IPC）机制来共享资源。

首先是共享内存，它允许多个进程共享同一块物理内存区域，从而可以直接读写对方进程的内存，达到数据共享的目的。操作系统会将这个物理内存区域映射到各个进程的虚拟地址空间，使得每个进程都可以访问到这个区域。

其次是管道，它允许一个进程向另一个进程发送数据，也可以接收另一个进程发送过来的数据。管道通常是单向的，而且只能在具有亲缘关系的进程之间使用。

还有消息队列，它可以在进程之间传递消息，从而实现进程之间的通信和同步。消息队列是一个存放消息的缓冲区，它允许一个进程往队列中写入消息，另一个进程从队列中读取消息。

最后是套接字，它是一种通用的进程间通信机制，可以在不同计算机之间进行通信。套接字通常用于网络编程，它允许一个进程向另一个进程发送数据，并且可以进行网络传输。

除了这些通信机制外，进程之间还可以通过文件共享、信号等方式进行通信。需要注意的是，进程之间共享资源可能会存在竞争和同步问题，需要使用锁、信号量、互斥量等同步机制来避免资源的冲突和错误。

#### 线程之间的通信方式

1. 共享变量：线程之间可以通过共享变量来进行通信。通过在多个线程之间共享同一块内存区域来实现，线程可以读取和修改共享变量的值，从而实现信息的传递和同步。
2. 信号量：信号量是一种计数器，用于控制多个线程对共享资源的访问。当一个线程需要访问共享资源时，它会首先尝试获取信号量，如果信号量的值大于0，则表示有可用的资源，线程可以访问共享资源并将信号量的值减1；如果信号量的值等于0，则表示没有可用的资源，线程需要等待其他线程释放资源后才能继续访问。
3. 互斥锁：互斥锁是一种同步机制，用于保护共享资源不被多个线程同时访问。当一个线程需要访问共享资源时，它会先获取互斥锁，如果互斥锁没有被其他线程占用，则表示可以访问共享资源，线程执行相应的操作并释放互斥锁；如果互斥锁已经被其他线程占用，则表示需要等待其他线程释放互斥锁后才能继续访问。
4. 条件变量：条件变量用于在线程间传递信号，它允许一个线程在满足某个特定条件之前等待其他线程发出信号。当一个线程需要等待某个条件成立时，它会先释放互斥锁并等待条件变量的信号，其他线程在满足条件时会发出信号并唤醒等待的线程，等待的线程被唤醒后会重新获取互斥锁并继续执行。



读写锁的底层实现

```
读写锁的底层实现通常是使用互斥锁和条件变量结合实现的。读写锁可以分为读锁和写锁，多个线程可以同时获取读锁，但只有一个线程可以获取写锁。当有线程获取写锁时，其他线程无法获取读锁和写锁，直到写锁被释放。

具体来说，读写锁的底层实现可以分为两种方式：

读写锁的互斥锁实现
使用一个互斥锁来保护读写锁的内部数据结构，比如读写计数器和等待队列等。读锁和写锁的获取和释放操作都需要先获取这个互斥锁，保证同一时刻只有一个线程在修改读写锁的内部状态。

当有线程需要获取读锁时，会判断是否有其他线程持有写锁，如果有则需要等待写锁释放，否则可以获取读锁。当有线程需要获取写锁时，会判断是否有其他线程持有读锁或者写锁，如果有则需要等待读锁和写锁全部释放，否则可以获取写锁。在获取和释放读锁和写锁时，需要修改读写计数器的值，以便正确地判断是否有其他线程持有读锁或者写锁。

读写锁的条件变量实现
使用两个条件变量来分别控制读锁和写锁的获取和释放。读写锁的内部数据结构可以只使用原子变量来保存读写计数器和等待队列等，避免使用互斥锁。

当有线程需要获取读锁时，会判断是否有其他线程持有写锁，如果有则需要等待写锁释放，否则可以获取读锁并增加读计数器。当有线程需要获取写锁时，会判断是否有其他线程持有读锁或者写锁，如果有则需要等待读锁和写锁全部释放，否则可以获取写锁并将写标志置为true。在释放读锁和写锁时，需要修改读写计数器的值，并且需要通知等待在条件变量上的其他线程。如果当前线程持有写锁，则需要通知等待写锁的线程；否则，如果读计数器为0，则需要通知等待写锁的线程，否则需要通知等待读锁的线程。

总之，读写锁的底层实现主要是通过互斥锁或条件变量等基本的同步原语来保证多个线程之间的访问正确性和一致性。不同的实现方式各有优缺点，应根据具体的场景来选择适当的实现方式。
```

## 锁的类型

```
互斥锁（Mutex Lock）：也叫互斥量，是一种基本的锁机制。只有拥有互斥锁的线程才能访问被保护的资源，其他线程必须等待互斥锁被释放才能访问。常用的互斥锁包括pthread_mutex_t（POSIX标准的互斥锁）、std::mutex（C++11标准库中的互斥锁）等。

读写锁（Read-Write Lock）：读写锁可以分为读锁和写锁，多个线程可以同时获取读锁，但只有一个线程可以获取写锁。当有线程获取写锁时，其他线程无法获取读锁和写锁，直到写锁被释放。读写锁可以提高多线程读操作的并发性能，适用于读操作频繁，写操作较少的场景。常用的读写锁包括pthread_rwlock_t（POSIX标准的读写锁）、std::shared_mutex（C++17标准库中的读写锁）等。
在C++中，读写锁的使用方式和互斥锁类似，可以使用std::shared_mutex来定义一个读写锁对象。和互斥锁不同的是，读写锁提供了两种操作：读操作：通过std::shared_lockstd::shared_mutex获取读锁，多个读操作可以同时持有读锁。写操作：通过std::unique_lockstd::shared_mutex获取写锁，只有一个写操作可以持有写锁，其他读写操作都需要等待写锁释放。读写锁的具体实现方式可以基于互斥锁和条件变量实现，也可以基于原子操作实现。不同的实现方式在性能和可靠性上可能存在差异，需要根据具体的应用场景选择合适的实现方式。

条件变量（Condition Variable）：条件变量用于线程之间的通信，可以等待某个条件满足后再继续执行。条件变量需要和互斥锁一起使用，等待条件时会释放互斥锁，等待结束后再重新获取互斥锁。常用的条件变量包括pthread_cond_t（POSIX标准的条件变量）、std::condition_variable（C++11标准库中的条件变量）等。

自旋锁（Spin Lock）：自旋锁是一种忙等待的锁机制，线程会一直循环检查锁是否可用，直到获取到锁为止。自旋锁适用于保护临界区很小、加锁时间很短的情况。常用的自旋锁包括pthread_spinlock_t（POSIX标准的自旋锁）、std::atomic_flag（C++11标准库中的原子标志）等。

递归锁（Recursive Lock）：递归锁允许同一线程多次获取锁，每次获取锁后需要相应的释放锁，否则会导致死锁。递归锁适用于需要递归调用加锁函数的场景。常用的递归锁包括pthread_mutex_t（POSIX标准的递归锁）、std::recursive_mutex（C++11标准库中的递归锁）等。
```

### 死锁

**死锁条件及解决**：

- 死锁是指两个或多个进程在等待对方释放资源而无限期地阻塞的情况。
- 死锁的四个必要条件是：互斥条件、请求和保持条件、不剥夺条件、循环等待条件。
- 解决死锁的策略包括预防、避免、检测与恢复。例如，一种预防策略是确保系统在分配资源之前检查该分配是否可能导致死锁。

#### 上下文开销问题

上下文开销是指当一个进程或线程从一个上下文切换到另一个上下文时，由于需要保存和恢复上下文信息所带来的开销。这些上下文信息包括程序计数器、寄存器、堆栈指针、状态字等。上下文切换是操作系统进行多任务调度的必要操作，但是频繁的上下文切换会带来较大的性能开销。

上下文切换的原因有多种，例如：

1. 抢占式调度：当一个进程或线程的时间片用完时，操作系统会抢占其CPU资源，并将其上下文信息保存下来，然后调度下一个进程或线程运行。
2. 阻塞式调度：当一个进程或线程需要等待某些事件发生时，如IO操作完成，操作系统会将其挂起，并将其上下文信息保存下来，等待事件发生后再恢复运行。
3. 中断处理：当硬件设备发生中断时，操作系统需要暂停当前进程或线程的执行，转而处理中断请求，这也需要进行上下文切换。

由于上下文开销的存在，操作系统在设计和实现调度算法时需要权衡进程/线程的切换频率和开销，以提高系统的性能和响应速度。通常的优化方法包括：

1. 尽量减少上下文切换的发生，如使用合适的调度算法、避免死锁和饥饿等问题。
2. 减少上下文信息的保存和恢复开销，如使用硬件支持的快速上下文切换技术、优化**内核态和用户态**之间的切换等。
3. 提高CPU的运行速度，以缩短上下文切换所带来的时间开销。

### 对进程进行管理

操作系统如何对进程进行管理（回答了一下进程调度的算法，不知道对不对）

进程的状态

初始化列表

#### 内存分页置换算法

1. 最优算法（Optimal Algorithm）：该算法会根据页面在未来的使用情况来决定置换哪些页面。具体来说，它会选择最长时间内不再被使用的页面进行置换。但是，由于无法预知未来页面的访问情况，因此最优算法的实际应用较少。
2. 先进先出算法（First In First Out, FIFO）：该算法会将最先进入内存的页面置换出去。该算法实现简单，但是由于没有考虑页面的使用情况，因此可能会导致一些常用的页面被频繁地置换出去，从而影响系统的性能。
3. 最近最少使用算法（Least Recently Used, LRU）：该算法会根据页面最近一次被使用的时间来决定置换哪些页面。具体来说，它会将最长时间内未被访问的页面进行置换。该算法相对于FIFO算法来说，能够更好地利用内存空间，但是实现起来比较复杂。
4. 时钟算法（Clock）：该算法会维护一个指针，指向当前要被检查的页面。当页面被访问时，会将页面的访问位设置为1。当需要置换页面时，时钟算法会从指针所指位置开始查找页面的访问位。如果访问位为0，则说明该页面未被使用，可以进行置换；否则将访问位设为0，继续查找下一个页面。该算法实现简单，但是可能会出现页面访问位频繁变化的情况，从而导致算法效率下降。



#### 同步机制

1. 自旋锁：当线程需要访问共享资源时，它会反复检查锁是否可用，直到获得锁为止，这个过程称为自旋。自旋锁适用于共享资源的锁定时间很短的情况，因为自旋锁会一直占用 CPU 时间。
2. 读写锁：读写锁允许多个线程同时读共享资源，但只允许一个线程写共享资源。这种锁适用于读操作比写操作更频繁的场景。
3. 条件变量：条件变量是一种用于线程间通信的机制，它可以让一个线程等待另一个线程的信号，当条件满足时，另一个线程会发送信号通知等待线程继续执行。条件变量通常和互斥锁一起使用，用于实现更复杂的同步操作。
4. 信号量：信号量是一种用于控制资源访问的计数器，它可以用来实现多个线程之间的同步和互斥。

除了这些同步机制外，还可以使用无锁算法和锁粒度更细的数据结构来避免锁带来的性能问题。但是需要注意的是，不同的同步机制和算法适用于不同的场景，需要根据具体的应用场景选择最合适的同步机制。

#### 抢占式和非抢占式

抢占式和非抢占式是操作系统中用于调度进程或线程的两种不同方式。

非抢占式调度是指进程或线程持有 CPU 的时间是不受外部干预的，只有在它自己执行完任务之后，才会主动释放 CPU 的控制权，让其他进程或线程获得 CPU 时间。在非抢占式调度中，进程或线程的运行时间是可预测的，但如果某个进程或线程出现了长时间的阻塞或死循环，会导致系统无法及时响应其他请求。

抢占式调度是指操作系统可以在任何时候中断当前进程或线程的执行，将 CPU 的控制权交给其他进程或线程，从而实现对进程或线程的强制抢占。在抢占式调度中，进程或线程的运行时间是不可预测的，但可以更好地保证系统的响应速度和并发性能。

一般来说，抢占式调度比非抢占式调度更加灵活和高效，因为它可以更好地处理系统资源的竞争和分配问题。但是，抢占式调度需要更多的系统开销和处理器时间，可能会影响系统的稳定性和响应速度。因此，在设计操作系统时，需要根据具体的应用场景和性能要求，选择合适的调度方式。



在执行过程的中间，执行被中断，而; 在非抢占式调度中，在执行过程中不会中断执行

抢先式调度会遭受从就绪状态到运行状态(反之亦然)之间进行切换以及维护就绪队列的开销。 另一方面，非抢占式调度不会遭受将进程从运行状态切换到就绪状态的开销。

当高优先级的进程频繁到达就绪队列时，低优先级的进程必须等待很长时间，并且可能会在抢占式调度中饿死。 而在非抢占式调度中，如果将CPU分配给具有较大突发时间的进程，则突发时间最小的进程可能不得不挨饿。

抢先式调度必须维护共享数据的完整性，因此这与成本相关，但非抢先式调度则不是这种情况。

这两个调度之间的主要区别在于，在非抢占式调度中，CPU被分配给进程，直到它完成执行或从运行状态切换到等待状态。 而在抢占式调度中，CPU将在有限的时间内分配给某个进程。

#### 操作系统的内存管理机制

不同进程之间的地址隔离是通过操作系统实现的。每个进程都有其独立的虚拟地址空间，其访问的内存地址不会直接映射到物理内存上，而是通过内存管理单元（MMU）进行地址转换。MMU负责将虚拟地址转换为物理地址，同时也负责检查进程对内存的访问权限。

操作系统通过使用分页和分段机制实现虚拟地址到物理地址的转换。在分页机制下，虚拟地址被划分为大小相等的页，每个页映射到物理内存中的一页。在分段机制下，虚拟地址被划分为不同的段，每个段映射到物理内存中的一块连续的地址空间。

操作系统还通过给每个进程分配独立的页表或段表来保证不同进程之间的地址隔离。每个进程的页表或段表中只包含该进程所拥有的内存地址的映射关系，从而防止进程之间相互访问彼此的内存。

此外，操作系统还可以使用内存保护机制来限制进程对内存的访问权限。例如，操作系统可以将某些内存区域标记为只读或禁止访问，从而保护系统的安全性和稳定性。

#### Notify和notifyAll的区别

前者随机唤醒一个该锁的线程，后者是全部唤醒

#### 并发编程

并发（Concurrency）是指同时执行多个任务的能力，通常通过多线程、多进程等技术来实现。在并发程序中，多个线程或进程可以同时运行，彼此之间互相协调、共享资源、完成任务。

以下是一些关于并发实现和流程的简单问题：

1. 什么是锁？

锁是一种并发控制机制，用于控制对共享资源的访问。在多线程或多进程环境中，如果多个线程或进程同时访问共享资源，可能会导致数据竞争和不一致的结果。锁通过互斥的方式，确保在同一时刻只有一个线程或进程能够访问共享资源，从而避免竞争和冲突。

1. 什么是线程池？

线程池是一种并发执行任务的机制，它维护了一定数量的线程，在需要执行任务时从池中分配线程，执行完任务后将线程返回到池中。线程池可以减少线程的创建和销毁，避免因线程频繁创建和销毁而导致的性能问题。

1. 什么是死锁？

死锁是指在并发程序中，两个或多个线程或进程因互相等待对方释放资源而陷入无限等待的状态。死锁是一种常见的并发问题，通常可以通过合理的资源分配和使用锁的策略来避免。

1. 并发程序的调试有什么难点？

并发程序的调试比较困难，因为多个线程或进程可以同时运行，彼此之间的执行顺序和交互不易预测。常见的并发调试问题包括数据竞争、死锁、活锁、饥饿等。为了解决这些问题，可以使用调试工具、日志记录、调试信息输出等技术，对并发程序进行逐步调试和排查问题。

### 信号

**Linux信号（Signals）**：

- 在Linux系统中，信号是一种用于进程间通信的机制，通常用于通知进程某个事件已经发生。
- 常见的信号包括：`SIGINT`（中断信号，如Ctrl+C）、`SIGTERM`（终止信号）、`SIGKILL`（不可捕获、不可忽略的终止信号）等。
- 进程可以通过特定的系统调用来发送信号，比如`kill`，也可以设置处理函数来响应接收到的信号。

### 多线程库

**多线程库**：

- 在Linux中，常用的多线程库包括POSIX线程（pthreads）、C++11线程库等。
- pthreads提供了创建和管理线程的功能，包括线程的创建、终止、同步（如互斥锁、条件变量）等。
- C++11中的线程库提供了更现代、更面向对象的线程管理方法，包括线程类、互斥量、条件变量、未来（futures）和承诺（promises）等。