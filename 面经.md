## C++语法

#### 引用和指针的区别

1. 语法：指针使用 * 号进行间接访问，而引用则不需要使用任何特殊符号。例如，对于一个指向整数的指针 p，我们可以通过 *p 访问该指针指向的整数值，而对于一个整数引用 r，我们可以直接使用 r 访问该引用所引用的整数值。
2. 可空性：指针可以是空指针，即指向空地址的指针，而引用必须始终引用一个已存在的对象。因此，在使用引用时，我们不需要检查空指针的情况。

- 指针是一个变量，存储的是地址，而引用是变量的别名
- 指针可以为空，而引用在定义的时候必须初始化
- 指针可以有多级，而引用只有一级
- 指针可以更改指向的对象，而引用不行

#### 写一个程序，读取文件内容做修改

其中的流程是怎么样的（内存管理、调度、IO）

#### 代码运行的过程

1. 编写源代码：首先需要编写C++源代码，使用文本编辑器或者集成开发环境（IDE）。
2. 预处理：在编译源代码之前，需要进行预处理。预处理器将处理源代码中的预处理指令，例如#include和#define指令，并生成预处理后的源代码文件。可以通过编译器的预处理选项来查看预处理后的源代码文件。
3. 编译：编译器将预处理后的源代码文件编译成目标代码（二进制代码），目标代码是特定平台上的机器代码，可以直接在计算机上运行。编译器会检查代码是否符合C++语法规范，并将代码转换成可执行代码。
4. 汇编assembled --- 产生object file
5. 链接：编译器生成的目标代码是一个独立的模块，需要进行链接才能生成可执行文件。链接器会将程序中使用的函数库和对象文件链接到一个可执行文件中，生成可执行代码。
6. 运行：最后，生成的可执行文件被操作系统加载到内存中，并执行程序。程序运行时，操作系统会为程序分配一定的内存空间，包括堆和栈，程序使用这些内存来存储变量和执行代码。

- C/C++编译过程：预编译=>编译=>汇编=>链接
- python编译过程：python解释器将源码=>字节码然后直接在解释器中运行

#### 操作运算符执行顺序

```cpp
表达式 b*=i+1 表示将变量 b 乘以 i+1 的结果再赋值给 b。它的执行顺序是先计算 i+1 的值，然后再将 b 乘以这个值，最后将结果赋值给变量 b。因此，其执行顺序为：
```



#### 类和接口有什么区别

类是一种描述对象的抽象，它定义了对象的属性和行为。类可以看作是对象的蓝图，它定义了对象的结构和行为，包括属性、方法和事件等。类可以被实例化为对象，通过实例化的对象来使用其属性和方法。

接口是一种定义行为的规范，它描述了一个对象应该具有哪些方法，但并不实现这些方法的代码。接口只定义了方法的签名，即方法的名称、返回类型和参数列表，但没有方法的实现。接口只是一个规范，它定义了对象应该具有的行为。

因此，类和接口的区别在于，类是一个具体的实现，它描述了对象的具体属性和行为，而接口只是一个行为的规范，它描述了一个对象应该具有哪些方法，但不涉及具体实现。类可以实现接口，以满足接口定义的行为规范，从而实现更高层次的抽象和代码重用。

#### 函数指针

函数指针是指向函数的指针变量，可以使用函数指针来动态调用函数。在函数指针中存储的是函数的地址，通过该指针可以访问和调用指向的函数。

假设有一个函数指针变量 func_ptr，指向一个函数 func，可以使用如下方式调用该函数：

```
(*func_ptr)(arg1, arg2, ...);
```

其中，(*func_ptr) 表示取出 func_ptr 指向的函数地址并调用该函数，arg1, arg2, ... 表示函数的参数。这样就可以通过函数指针来调用指向的函数。

例如，假设有一个函数指针变量 int (*add_ptr)(int, int)，指向一个加法函数 add，可以使用如下方式调用该函数：

```
int result = (*add_ptr)(a, b);
```

其中，a 和 b 是加法函数的两个参数，result 是函数的返回值。这样就可以通过函数指针来调用加法函数。

需要注意的是，函数指针变量必须先指向一个函数，才能使用它来调用函数。否则会出现运行时错误。另外，函数指针还可以作为参数传递给其他函数，或作为函数的返回值返回给调用者，从而实现更加灵活的程序设计。

#### strlen和sizeof

在C语言中，strlen()和sizeof()函数都可以用于处理字符串，但它们的作用不同。

1. strlen()函数

strlen()函数用于计算字符串的长度，即字符串中字符的个数，不包括字符串末尾的'\0'。strlen()函数的函数原型为：

```
arduinoCopy code
size_t strlen(const char *str);
```

其中，str为待计算长度的字符串，返回值为字符串的长度，返回值的类型为size_t。例如，对于字符串"hello"，strlen()函数的返回值为5。

1. sizeof()运算符

sizeof()运算符用于计算数据类型或变量所占的内存空间大小，包括数据类型或变量中的所有字节，包括字符串末尾的'\0'。sizeof()运算符的语法为：

```
scssCopy code
sizeof(type)或sizeof(expr)
```

其中，type为数据类型，expr为变量或表达式。sizeof()运算符的返回值的类型为size_t，它表示数据类型或变量所占的字节数。

因此，如果使用sizeof()运算符计算一个字符串的大小，将包括字符串末尾的'\0'，例如，对于字符串"hello"，使用sizeof()运算符计算的大小为6，因为字符串中有5个字符和一个'\0'字符。

需要注意的是，strlen()函数计算的是字符串中实际的字符个数，而sizeof()运算符计算的是字符串在内存中所占的字节数。在使用字符串时，应根据实际需求选择使用strlen()函数还是sizeof()运算符。



头文件保护（Header Guard）或者pragma once

#### c++11新特性

##### bind绑定器

```cpp
#include <iostream>
#include <functional>

using namespace std::placeholders;

int func(int a, int b, int c)
{
    return a + b + c;
}

struct Foo {
    int func(int a, int b) { return a + b; }
};

int main()
{
    // 绑定函数
    auto f1 = std::bind(func, _1, 2, _2);
    int result1 = f1(1, 3);  // 调用func(1, 2, 3)，返回6
    std::cout << result1 << std::endl;

    // 绑定成员函数
    Foo foo;
    auto f2 = std::bind(&Foo::func, &foo, _1, _2);
    int result2 = f2(1, 2);  // 调用foo.func(1, 2)，返回3
    std::cout << result2 << std::endl;

    // 绑定Lambda表达式
    auto f3 = std::bind([](int a, int b, int c) { return a + b + c; }, _2, _1, 3);
    int result3 = f3(1, 2);  // 调用Lambda表达式(2, 1, 3)，返回6
    std::cout << result3 << std::endl;
    // lambda表达式不需要自己写太多的，匿名函数

    return 0;
}

```

##### lambda表达式

##### auto和decltype类型推导

静态编译的时候决定

```cpp
const int x = 5;
auto y = x; // y is int
```



```cpp
for(vector<int>::const_iterator it = v.begin(); it != v.end(); ++it);
// 可以改写为
for(auto it = v.begin(); it != v.end(); ++it);
```

decltype ⽤于获取⼀个表达式的类型，⽽不对表达式进⾏求值（类似于 sizeof ）。 decltyp(e) 规则如下：

若 e 为⼀个⽆括号的变ᰁ、函数参数、类成员，则返回类型为该变ᰁ/参数/类成员在源程序中的声明类型； 否则的话，根据表达式的值分类（value categories），设 T 为 e 的类型： 的类型： 

若 e 是⼀个左值（lvalue，即“可寻址值”），返回 T& ； 

若 e 是⼀个临终值（xvalue），则返回值为 T&& ； 

若 e 是⼀个纯右值（prvalue），则返回值为 T 。

```cpp
int x = 5;
int arr[] = {1, 2, 3};
std::vector<int> vec = {4, 5, 6};

decltype(x + 1) a = 6;  // int
decltype(arr[0]) b = 2;  // int&
decltype(vec.size()) c = 3;
decltype(true ? x : arr[1]) d = 5; // int&
According to the C++ standard (§7.14 [expr.cond]), when you use the conditional operator (? :) with two operands of different types, the result is a reference to a common type that both operands can be converted to. In this case, the common type is int&, since int can be converted to int&, but not vice versa.

Therefore, when you use decltype(true ? x : arr[1]), the result is int&, since that is the type of the expression true ? x : arr[1].
```

右值引⽤，std::move, std::emplace_back, 基于范围的for循环

#### default 和 delete 

我们知道编译器会为类⾃动⽣成⼀些⽅法，⽐如构造和析构函数（完整的列表⻅ Effective C++: Item 5）。 现在我们可以显式地指定和禁⽌这些⾃动⾏为了。 在上述 classA 中定义了 classA(T value) 构造函数，因此编译器不会默认⽣成⼀个⽆参数的构造函数了， 如 果我们需要可以⼿动声明，或者直接 = default 。

#### C++ 中内存分配情况 

栈：由编译器管理分配和回收，存放局部变量和函数参数。

堆：由程序员管理，需要⼿动 new malloc delete free 进⾏分配和回收，空间较⼤，但可能会出现内存泄漏和空闲 碎⽚的情况。 

全局/静态存储区：分为初始化和未初始化两个相邻区域，存储初始化和未初始化的全局变量和静态变量。 全局静态变量在程序启动时分配内存，直到程序结束才被释放。`static `

常量存储区：存储常量，⼀般不允许修改。 

代码区：存放程序的⼆进制代码。



以下是常见的内存分区：

1. 栈（Stack）：栈是一种后进先出（Last In First Out，LIFO）的数据结构，它用于存储函数调用时的局部变量、函数参数、返回地址等。在程序执行时，每个函数都会有一个独立的栈帧，它包含了该函数的局部变量和参数等信息。
2. 堆（Heap）：堆是一种动态内存分配方式，它用于存储程序运行时动态申请的内存。通常由程序员手动管理，在程序中通过 malloc、calloc、realloc 等函数动态分配内存，使用完毕后需要通过 free 函数释放内存。
3. 全局静态区（Global/static area）：全局静态区存储了全局变量和静态变量，这些变量的生命周期与程序的执行时间相同，存储在程序的数据段中。全局变量默认初始化为0，静态变量默认初始化为NULL。
4. 常量区（Constant area）：常量区是存储程序中不可变量的地方，如字符串常量等。它通常存储在程序的代码段中，是只读的。
5. 代码区（Code area）：代码区存储了程序的执行代码，包括函数代码和指令代码等。

这些内存分区的划分方式和使用规则可能因编程语言和操作系统不同而有所差异，但是了解这些内存分区的基本概念对于程序员来说是非常重要的，可以帮助他们更好地进行内存管理和调试。

#### C++ 中 const 和 static 关键字（定义，⽤途） 

static 作⽤：控制变量的存储⽅式和可⻅性。 

作⽤⼀：修饰局部变量：⼀般情况下，对于局部变量在程序中是存放在栈区的，并且局部的⽣命周期在包含语句块 执⾏结束时便结束了。但是如果⽤ static 关键字修饰的话，该变ᰁ便会存放在静态数据区，其⽣命周期会⼀直延续 到整个程序执⾏结束。但是要注意的是，虽然⽤ static 对局部变ᰁ进⾏修饰之后，其⽣命周期以及存储空间发⽣了 变化，但其作⽤域并没有改变，作⽤域还是限制在其语句块。 

作⽤⼆：修饰全部变量：对于⼀个全局变量，它既可以在本⽂件中被访问到，也可以在同⼀个⼯程中其它源⽂件被 访问(添加 extern进⾏声明即可)。⽤ static 对全局变量进⾏修饰改变了其作⽤域范围，由原来的整个⼯程可⻅变成 了本⽂件可⻅。 

作⽤三：修饰函数：⽤ static 修饰函数，情况和修饰全局变ᰁ类似，也是改变了函数的作⽤域。 

作⽤四：修饰类：如果 C++ 中对类中的某个函数⽤ static 修饰，则表示该函数属于⼀个类⽽不是属于此类的任何 特定对象；如果对类中的某个变ᰁ进⾏ static 修饰，则表示该变ᰁ以及所有的对象所有，存储空间中只存在⼀个副 本，可以通过；类和对象去调⽤。 （补充：静态⾮常ᰁ数据成员，其只能在类外定义和初始化，在类内仅是声明⽽已。） 

作⽤五：类成员/类函数声明 static 函数体内 static 变ᰁ的作⽤范围为该函数体，在类中，`static` 用于声明静态成员。静态成员是属于类本身的，而不是属于类的每个实例的。因此，静态成员可以被所有实例共享，并且可以通过类名直接访问，而不需要创建实例。

如果在类中声明一个静态成员函数，那么该函数将不依赖于任何实例的状态，并且可以被直接调用，而不需要先创建实例。这意味着静态成员函数可以在没有类实例的情况下执行，并且可以访问静态成员变量和其他静态成员函数，但不能访问非静态成员变量和非静态成员函数，因为它们是与实例相关联的。

static 类对象必须要在类外进⾏初始化，static 修饰的变ᰁ先于对象存在，所以 static 修饰的变ᰁ要在类外初 始化； 由于 static 修饰的类成员属于类，不属于对象，因此 static 类成员函数是没有 this 指针，this 指针是指向本 对象的指针，正因为没有 this 指针，所以 static 类成员函数不能访问⾮ static 的类成员，只能访问 static修饰 的类成员； static 成员函数不能被 virtual 修饰，static 成员不属于任何对象或实例，所以加上 virtual 没有任何实际意 义；静态成员函数没有 this 指针，虚函数的实现是为每⼀个对象分配⼀个 vptr 指针，⽽ vptr 是通过 this 指 针调⽤的，所以不能为 virtual；虚函数的调⽤关系，this->vptr->ctable->virtual function。 



const 关键字：含义及实现机制 const 修饰基本类型数据类型：基本数据类型，修饰符 const 可以⽤在类型说明符前，也可以⽤在类型说明符后， 其结果是⼀样的。在使⽤这些常ᰁ的时候，只要不改变这些常ᰁ的值即可。 

const 修饰指针变ᰁ和引⽤变ᰁ：例如，`const int *p` 定义了一个指向整数常量的指针。这意味着 `p` 可以指向任何整数，但是不能通过 `p` 修改所指向的整数的值，因为该整数被定义为常量。另一方面，`*const` 表示常量指针，它将指针本身定义为常量，而指针所指向的内容可以被修改

const 应⽤到函数中：作为参数的 const 修饰符：调⽤函数的时候，⽤相应的变ᰁ初始化 const 常量，则在函数体 中，按照 const 所修饰的部分进⾏常量化，保护了原对象的属性。 [注意]：参数 const 通常⽤于参数为指针或引⽤ 的情况; 作为函数返回值的 const 修饰符：声明了返回值后，const 按照"修饰原则"进⾏修饰，起到相应的保护作 ⽤。 



const 在类中的⽤法：

1. 常量成员变量

在类中使用 `const` 关键字可以定义常量成员变量，即该变量的值不能被修改。常量成员变量必须在类定义中初始化，并且不能在类的任何函数中修改。

```
c++Copy codeclass MyClass {
public:
    const int MAX_VALUE = 100;  // 常量成员变量

    int getValue() const {
        // MAX_VALUE = 200;  // 错误：常量成员变量不能修改
        return MAX_VALUE;
    }
};
```

上面的代码中，`MAX_VALUE` 是一个常量成员变量，它的值被初始化为 `100`。在成员函数 `getValue` 中，使用 `const` 关键字指定该函数为常量成员函数，并且不能修改 `MAX_VALUE` 的值。

1. 常量成员函数

在类中使用 `const` 关键字可以定义常量成员函数，即该函数不能修改任何成员变量的值。常量成员函数可以读取成员变量的值，但不能修改它们。

```
c++Copy codeclass MyClass {
public:
    int getValue() const {  // 常量成员函数
        // myValue = 200;  // 错误：常量成员函数不能修改成员变量的值
        return myValue;
    }

private:
    int myValue;
};
```

上面的代码中，`getValue` 是一个常量成员函数，它不能修改成员变量 `myValue` 的值，只能读取它的值。

## CMAKE

target_link_libraries(my_program PRIVATE my_static_library)

1. `PRIVATE`：当这个选项在指定目标上设置编译要求时，这些要求只应用于该目标本身，不会传递给其他的目标。
2. `PUBLIC`：当这个选项在指定目标上设置编译要求时，这些要求既应用于该目标本身，也会传递给其他依赖于这个目标的目标。
3. `INTERFACE`：当这个选项在指定目标上设置编译要求时，这些要求不应用于该目标本身，但会传递给其他依赖于这个目标的目标。

在CMake中，`PUBLIC`，`PRIVATE` 和 `INTERFACE` 这些关键字用于指定库目标的编译要求。这些要求包括编译器标志，预处理器定义，头文件搜索路径等等。这些编译要求可以通过 `target_compile_definitions()`，`target_compile_options()`，`target_include_directories()`，`target_link_libraries()` 等命令设置。

下面是这些关键字的详细说明：

\1. `PRIVATE`：当这个选项在指定目标上设置编译要求时，这些要求只应用于该目标本身，不会传递给其他的目标。

\2. `PUBLIC`：当这个选项在指定目标上设置编译要求时，这些要求既应用于该目标本身，也会传递给其他依赖于这个目标的目标。

\3. `INTERFACE`：当这个选项在指定目标上设置编译要求时，这些要求不应用于该目标本身，但会传递给其他依赖于这个目标的目标。

以下面的代码为例：

\```cmake
add_library(mylib mylib.cpp)
add_executable(myexe main.cpp)
target_link_libraries(myexe PRIVATE mylib)
\```

在这个例子中，`myexe`私有地链接到了`mylib`。这意味着`mylib`的公开（`PUBLIC`）和接口（`INTERFACE`）编译要求将被用于`myexe`，但这些要求不会进一步传递给`myexe`的依赖项。

反之，如果我们将`PRIVATE`更改为`PUBLIC`：

\```cmake
target_link_libraries(myexe PUBLIC mylib)
\```

这就意味着`mylib`的公开（`PUBLIC`）和接口（`INTERFACE`）编译要求将被用于`myexe`，并且如果有其他的目标链接到`myexe`，那么这些要求也会传递给那些目标。

这些都是 CMake 的命令，用于设置构建目标的特定属性。具体来说：

\1. `target_compile_definitions()`: 该命令用于为目标添加编译预处理器定义。例如：

  \```cmake
  target_compile_definitions(my_target PRIVATE MY_DEFINITION)
  \```

  这行代码将为 `my_target` 添加一个预处理器定义 `MY_DEFINITION`。在编译 `my_target` 时，编译器将把 `MY_DEFINITION` 当作已定义的宏。

\2. `target_compile_options()`: 该命令用于为目标添加额外的编译器选项。例如：

  \```cmake
  target_compile_options(my_target PRIVATE -Wall)
  \```

  这行代码将为 `my_target` 添加 `-Wall` 编译器选项，该选项会让编译器为可能的问题产生警告。

\3. `target_include_directories()`: 该命令用于为目标添加额外的头文件搜索路径。例如：

  \```cmake
  target_include_directories(my_target PRIVATE include/)
  \```

  这行代码将 `include/` 目录添加到 `my_target` 的头文件搜索路径中。当编译 `my_target` 时，编译器会在这个目录中查找头文件。

\4. `target_link_libraries()`: 该命令用于将库链接到目标。例如：

  \```cmake
  target_link_libraries(my_target PRIVATE my_lib)
  \```

  这行代码将 `my_lib` 链接到 `my_target`。当链接 `my_target` 时，链接器会查找 `my_lib` 库。

在所有这些命令中，`PRIVATE`、`PUBLIC` 和 `INTERFACE` 这些关键字用来指定应该如何处理这些编译要求。`PRIVATE` 表示只有目标自己会使用这些要求，`PUBLIC` 表示既用于目标自己，也用于链接到目标的其他目标，`INTERFACE` 表示只用于链接到目标的其他目标。

#### smart pointer智能指针

valgrind检查内存泄漏，或者用智能指针

智能指针和垃圾回收都是用于管理动态内存的技术，但是它们的实现和使用方式有很大的不同。

智能指针是一种C++语言特有的机制，它使用对象管理动态内存，使得程序员不需要手动调用delete操作释放内存。智能指针是一个类，其对象的行为类似于原始指针，但是具有自动释放内存的功能。智能指针会在对象生命周期结束时自动释放内存，避免了内存泄漏的风险。C++标准库中提供了两种智能指针：shared_ptr和unique_ptr。其中shared_ptr可以共享所有权，而unique_ptr只能拥有所有权。

垃圾回收是一种内存管理技术，用于自动回收无用的内存。与智能指针不同，垃圾回收器是一种运行时机制，它会扫描程序中的对象，并自动回收无用的对象所占用的内存。垃圾回收通常是由虚拟机或者解释器来实现的，例如Java虚拟机中的垃圾回收机制。垃圾回收器可以大大减少程序员的内存管理工作，但是也会带来一些运行时开销，例如暂停应用程序来进行垃圾回收。

总之，智能指针和垃圾回收都是用于动态内存管理的技术，但是它们的实现和使用方式有很大的不同。智能指针是一种编译时机制，需要程序员手动编写代码使用，而垃圾回收是一种运行时机制，需要虚拟机或解释器来自动回收无用的内存。



****⾸先，说⼀下为什么要使⽤智能指针：**

**智能指针其作⽤是管理⼀个指针，避免咋们程序员申请的空间 在函数结束时忘记释放，造成内存泄漏这种情况滴发⽣。 

然后使⽤智能指针可以很⼤程度上的避免这个问题，因为智能指针就是⼀个类，当超出了类的作⽤域是，类会⾃动 调⽤析构函数，析构函数会⾃动释放资源。

所以智能指针的作⽤原理就是在函数结束时⾃动释放内存空间，不需要⼿动释放内存空间

**常⽤接⼝ T 是模板参数, 也就是传⼊的类型； 

```cpp
T* get();
T& operator*();
T* operator->();
T& operator=(const T& val);
T* release();
void reset (T* ptr = nullptr);
```

T 是模板参数, 也就是传⼊的类型； 

- get() ⽤来获取 auto_ptr 封装在内部的指针, 也就是获取原⽣指针； 
- operator() ᯿载 , operator->() ᯿载了->, operator=()᯿载了=； 
- realease() 将 auto_ptr 封装在内部的指针置为 nullptr, 但并不会破坏指针所指向的内容, 函数返回的是内部指 针置空之前的值； 
- 直接释放封装的内部指针所指向的内存, 如果指定了 ptr 的值, 则将内部指针初始化为该值 (否则将其设置为 nullptr；

**auto_ptr**

```cpp
auto_ptr<std::string> p1 (new string ("hello"));
auto_ptr<std::string> p2;
p2 = p1; //auto_ptr 不会报错.
```

此时不会报错，p2 剥夺了 p1 的所有权，但是当程序运⾏时访问 p1 将会报错。所以 auto_ptr 的缺点是：存在潜 在的内存崩溃问题！

**unique_ptr**

unique_ptr 实现独占式拥有或严格拥有概念，保证同⼀时间内只有⼀个智能指针可以指向该对象。它对于避免资 源泄露特别有⽤。 采⽤所有权模式，还是上⾯那个例⼦

```cpp
unique_ptr<string> p3 (new string (auto));//#4
unique_ptr<string> p4；//#5
p4 = p3;//此时会报错
```

编译器认为 p4=p3 ⾮法，避免了 p3 不再指向有效数据的问题。 因此，unique_ptr ⽐ auto_ptr 更安全。

**shared_ptr**

shared_ptr 实现共享式拥有概念，多个智能指针可以指向相同对象，该对象和其相关资源会在“最后⼀个引⽤被销 毁”时候释放。从名字 share 就可以看出了资源可以被多个指针共享，它使⽤计数机制来表明资源被⼏个指针共 享。 可以通过成员函数 use_count() 来查看资源的所有者个数，除了可以通过 new 来构造，还可以通过传⼊auto_ptr, unique_ptr,weak_ptr 来构造。当我们调⽤ release() 时，当前指针会释放资源所有权，计数减⼀。当计数等于 0 时，资源会被释放。 shared_ptr 是为了解决 auto_ptr 在对象所有权上的局限性 (auto_ptr 是独占的)，在使⽤引⽤计数的机制上提供了 可以共享所有权的智能指针。

1. 在创建shared_ptr对象时，会分配两个空间：一个用于存储指向动态分配内存的指针，另一个用于存储该内存的引用计数（refcount）。

**weak_ptr**

weak_ptr 是⼀种不控制对象⽣命周期的智能指针，它指向⼀个 shared_ptr 管理的对象。进⾏该对象的内存管理 的是那个强引⽤的 shared_ptr。 weak_ptr 只是提供了对管理对象的⼀个访问⼿段。weak_ptr 设计的⽬的是为配合 shared_ptr ⽽引⼊的⼀种智 能指针来协助 shared_ptr ⼯作，它只可以从⼀个 shared_ptr 或另⼀个 weak_ptr 对象构造,，它的构造和析构不会 引起引⽤记数的增加或减少。 weak_ptr 是⽤来解决 shared_ptr 相互引⽤时的死锁问题，如果说两个 shared_ptr 相互引⽤，那么这两个指针的 引⽤计数永远不可能下降为0，也就是资源永远不会释放。它是对对象的⼀种弱引⽤，不会增加对象的引⽤计数， 和 shared_ptr 之间可以相互转化，shared_ptr 可以直接赋值给它，它可以通过调⽤ lock 函数来获得 shared_ptr。 当两个智能指针都是 shared_ptr 类型的时候，析构时两个资源引⽤计数会减⼀，但是两者引⽤计数还是为 1，导 致跳出函数时资源没有被释放（的析构函数没有被调⽤），解决办法：把其中⼀个改为weak_ptr就可以。

#### C++ 的四种强制转换 

C++ 的四种强制转换包括：static_cast, dynamic_cast, const_cast, reinterpret_cast 



static_cast：明确指出类型转换，⼀般建议将隐式转换都替换成显示转换，因为没有动态类型检查，上⾏转换 （派⽣类->基类）安全，下⾏转换（基类->派⽣类） 不安全，所以主要执⾏⾮多态的转换操作； dynamic_cast：专⻔⽤于派⽣类之间的转换，type-id 必须是类指针，类引⽤或 void*，对于下⾏转换是安全 的，当类型不⼀致时，转换过来的是空指针，⽽static_cast，当类型不⼀致时，转换过来的事错误意义的指 针，可能造成⾮法访问等问题。 const_cast：专⻔⽤于 const 属性的转换，去除 const 性质，或增加 const 性质， 是四个转换符中唯⼀⼀个 可以操作常ᰁ的转换符。 reinterpret_cast：不到万不得已，不要使⽤这个转换符，⾼危操作。使⽤特点： 从底层对数据进⾏᯿新解 释，依赖具体的平台，可移植性差； 可以将整形转 换为指针，也可以把指针转换为数组；可以在指针和引⽤ 之间进⾏肆⽆忌惮的转换。



1. 静态转换（static_cast）

```cpp
int a = 10;
double b = static_cast<double>(a);  // 将整型变量a转换为双精度浮点型变量b
class Base {};
class Derived : public Base {};
Base* basePtr = new Derived;
Derived* derivedPtr = static_cast<Derived*>(basePtr);  // 将基类指针转换为派生类指针

//明确指出类型转换，⼀般建议将隐式转换都替换成显示转换，因为没有动态类型检查，上⾏转换 （派⽣类->基类）安全，下⾏转换（基类->派⽣类） 不安全，所以主要执⾏⾮多态的转换操作
```

1. 动态转换（dynamic_cast）

```cpp
class Base {
public:
    virtual void print() { cout << "Base class" << endl; }
};
class Derived : public Base {
public:
    void print() { cout << "Derived class" << endl; }
};
Base* basePtr = new Derived;
Derived* derivedPtr = dynamic_cast<Derived*>(basePtr);  // 将基类指针转换为派生类指针
if (derivedPtr != nullptr) {
    derivedPtr->print();  // 调用Derived类的print()函数
}
// dynamic_cast：专⻔⽤于派⽣类之间的转换，type-id 必须是类指针，类引⽤或 void*，对于下⾏转换是安全 的，当类型不⼀致时，转换过来的是空指针，⽽static_cast，当类型不⼀致时，转换过来的是错误意义的指 针，可能造成⾮法访问等问题
```

1. 常量转换（const_cast）

```cpp
const int a = 10;
int& b = const_cast<int&>(a);  // 将常量变量a转换为非常量变量b
const int* constPtr = new int(10);
int* ptr = const_cast<int*>(constPtr);  // 将常量指针转换为非常量指针
*ptr = 20;
//const_cast：专⻔⽤于 const 属性的转换，去除 const 性质，或增加 const 性质， 是四个转换符中唯⼀⼀个 可以操作常ᰁ的转换符
```

1. 重新解释转换（reinterpret_cast）

```cpp
int a = 10;
int* ptr = &a;
uintptr_t addr = reinterpret_cast<uintptr_t>(ptr);  // 将指针类型转换为整数类型
arduinoCopy codeint a = 10;
int* ptr = reinterpret_cast<int*>(&a);  // 将整数类型转换为指针类型
*ptr = 20;
```

#### 深拷贝和浅拷贝

浅拷贝是指复制一个对象时，只复制其引用，而不是复制对象本身。也就是说，新对象和原对象会共享相同的内存地址，修改其中一个对象的值会影响到另一个对象的值。浅拷贝通常是比较快速和高效的，因为只需要复制引用而不是复制整个对象。

深拷贝是指复制一个对象时，会创建一个新的对象，新对象和原对象拥有相同的属性值，但是占用不同的内存地址。修改其中一个对象的值不会影响到另一个对象的值。深拷贝通常比较慢和低效，因为需要复制整个对象。

在编程中，如果需要创建一个与原对象完全独立的对象，可以使用深拷贝；如果只需要创建一个与原对象共享某些数据，可以使用浅拷贝。具体选择哪种方式取决于具体的需求。

#### 面向对象三大特征

#### 继承的实现

#### 多态

##### 虚函数（动态多态）

虚函数的使用需要满足以下两个条件：

1. 在父类中声明虚函数：在父类中将需要重写的方法声明为虚函数，使用virtual关键字。例如：

```
class Animal {
public:
  virtual void makeSound() {
    std::cout << "Animal makes a sound" << std::endl;
  }
};
```

1. 在子类中重写虚函数：在子类中重写父类的虚函数，使用override关键字。例如：

```
class Cat : public Animal {
public:
  void makeSound() override {
    std::cout << "Meow!" << std::endl;
  }
};
```

重写虚函数时，需要满足函数签名（函数名、参数类型和返回类型）与父类中声明的虚函数一致，否则会被视为一个新的函数。

虚函数的调用是动态绑定的，即在运行时才确定调用哪个函数，而不是在编译时确定。例如：

```
Animal* animal = new Cat();
animal->makeSound();  // 输出 "Meow!"
```

在上面的示例中，animal指向的是Cat对象，但是通过Animal类型的指针调用makeSound()方法时，实际上调用的是Cat类中重写的makeSound()方法，因为makeSound()是虚函数，动态绑定了正确的方法。

总之，虚函数是C++中实现多态的重要手段，通过使用虚函数，可以使程序更加灵活和可扩展。

虚函数，它虚就虚在所谓"推迟联编"或者"动态联编"上，一个类函数的调用并不是在编译时刻被确定的，而是在运行时刻被确定的。加了虚函数会根据动态类型去执行函数，包括执行destructor

在某基类中声明为 virtual 并在一个或多个[派生类](https://baike.baidu.com/item/派生类/9589520)中被重新定义的成员函数，用法格式为：[virtual](https://baike.baidu.com/item/virtual/3371630) 函数返回类型 函数名（[参数表](https://baike.baidu.com/item/参数表/4127102)） {[函数体](https://baike.baidu.com/item/函数体/10681316)}；实现[多态性](https://baike.baidu.com/item/多态性/4725624)，通过指向派生类的基类指针或引用，访问派生类中同名覆盖成员函数。

纯虚函数，virtual void funtion1()=0 主要是把函数的细节交给子类去完成

##### 虚函数相关（虚函数表，虚函数指针），虚函数的实现原理 

⾸先我们来说⼀下，C++中多态的表象，在基类的函数前加上 virtual 关键字，在派⽣类中᯿写该函数，运⾏时将会 根据对象的实际类型来调⽤相应的函数。如果对象类型是派⽣类，就调⽤派⽣类的函数，如果是基类，就调⽤基类 的函数。 **实际上，当⼀个类中包含虚函数时，编译器会为该类⽣成⼀个虚函数表，保存该类中虚函数的地址，**同样，派⽣类 继承基类，派⽣类中⾃然⼀定有虚函数，所以编译器也会为派⽣类⽣成⾃⼰的虚函数表。当我们定义⼀个派⽣类对 象时，**编译器检测该类型有虚函数，所以为这个派⽣类对象⽣成⼀个虚函数指针，指向该类型的虚函数表，**这个虚 函数指针的初始化是在构造函数中完成的。 后续如果有⼀个基类类型的指针，指向派⽣类，那么当调⽤虚函数时，就会根据所指真正对象的虚函数表指针去寻 找虚函数的地址，也就可以调⽤派⽣类的虚函数表中的虚函数以此实现多态。 

补充：**如果基类中没有定义成 virtual，那么进⾏ Base B; Derived D; Base *p = D; p->function(); 这种情况下调⽤ 的则是 Base 中的 function()。因为基类和派⽣类中都没有虚函数的定义，那么编译器就会认为不⽤留给动态多态 的机会，就事先进⾏函数地址的绑定（早绑定）**，详述过程就是，定义了⼀个派⽣类对象，⾸先要构造基类的空 间，然后构造派⽣类的⾃身内容，形成⼀个派⽣类对象，那么在进⾏类型转换时，直接截取基类的部分的内存，编 译器认为类型就是基类，那么（函数符号表［不同于虚函数表的另⼀个表］中）绑定的函数地址也就是基类中函数 的地址，所以执⾏的是基类的函数。

虚函数相关（虚函数表，虚函数指针），虚函数的实现原理 

在菱形继承中，子类从它的两个父类中继承了同一个基类的成员变量和成员函数。如果这些成员变量和成员函数没有正确地处理，就可能会导致内存浪费和访问错误。具体来说，如果子类尝试访问它的基类成员时，可能会访问到两个不同的实例，这可能导致预期之外的行为。

为了解决这个问题，C++引入了虚继承。虚继承是一种特殊的继承方式，它确保基类在继承层次结构中只有一个实例。在使用虚继承时，基类的成员变量和成员函数只有一个实例，因此菱形继承中的问题得以解决。

在内存中，虚继承是通过添加一个虚基类表来实现的，该表记录了虚基类的偏移量和指向虚基类实例的指针。这样，子类可以通过虚基类表来访问基类的成员，而不会访问到多个实例。因此，在使用虚继承时，内存分布方案会有所不同。



虚函数表是在编译阶段建立的，通常由编译器在类的代码中自动生成。虚函数表中包含了该类所有虚函数的地址，以及用于动态绑定虚函数的虚函数指针（vptr）。

虚函数指针是在类的实例化过程中建立的。当一个对象被创建时，会分配一块内存来存储对象的数据成员和虚函数指针。虚函数指针指向对象所属类的虚函数表，以便在运行时进行动态绑定。如果类中存在虚函数，编译器会在该类中添加一个虚函数指针vptr，这个指针在实例化时会被赋值指向该类的虚函数表。

当一个对象调用虚函数时，会根据对象的虚函数指针指向的虚函数表来查找虚函数的地址，然后调用相应的函数。由于虚函数指针是每个对象独有的，所以同一类的不同对象可能会有不同的虚函数指针，它们指向的虚函数表也可能不同。

需要注意的是，虚函数表和虚函数指针只对于带有虚函数的类才会存在。如果类中没有虚函数，那么它的实例化过程中也不会分配虚函数指针和虚函数表。

#### 析构函数⼀般写成虚函数的原因 

直观的讲：是为了降低内存泄漏的可能性。举例来说就是，⼀个基类的指针指向⼀个派⽣类的对象，在使⽤完毕准 备销毁时，如果基类的析构函数没有定义成虚函数，那 么编译器根据指针类型就会认为当前对象的类型是基类，调 ⽤基类的析构函数 （该对象的析构函数的函数地址早就被绑定为基类的析构函数），仅执⾏基类的析构，派⽣类的 ⾃身内容将⽆法被析构，造成内存泄漏。 如果基类的析构函数定义成虚函数，那么编译器就可以根据实际对象，执⾏派⽣类的析构函数，再执⾏基类的析构 函数，成功释放内存。

基类 = new 派生类

动态派生类，静态基类。

只会执行静态的destructor

#### 构造函数为什么⼀般不定义为虚函数

构造函数一般不定义为虚函数是因为构造函数的调用是在对象创建的过程中完成的，而在对象创建的过程中，虚函数机制还没有开始建立，因此无法通过构造函数调用虚函数。换句话说，**构造函数执行的时候，对象还没有完全创建出来，其虚函数表还没有建立起来，此时调用虚函数是不安全的。如果将构造函数定义为虚函数，可能会导致无法预料的行为发生。**

另外，C++规定，虚函数是通过指向对象的指针或引用来调用的，而在对象构造过程中，**指向对象的指针或引用还没有建立，因此无法调用构造函数的虚函数。**

最后，构造函数的**主要目的是为对象分配内存、初始化对象的成员变量等等，而不是执行多态的操作。**因此，在构造函数中不需要定义为虚函数。



#### new / delete ，malloc / free 区别

new：此操作符分配的内存空间是在自由存储区；

malloc：申请的内存是在堆空间。

C/C++的内存通常分为：堆、栈、自由存储区、全局/静态存储区、常量存储区。可能除了自由存储区，其他的内存分布大家应该都比较熟悉。

**堆** 是C语言和操作系统的术语，堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当运行程序调用malloc()时就会从中分配，调用free()归还内存。那什么是自由存储区呢？

 

都可以⽤来在堆上分配和回收空间。

new /delete 是操作符，malloc/free 是库函数。 

执⾏ new 实际上执⾏两个过程：

1.分配未初始化的内存空间（malloc）；

2.使⽤对象的构造函数对空间进⾏初始化；返回空间的⾸地址。如果在第⼀步分配空间中出现问题，则抛出 std::bad_alloc 异常，或被某个设定的异常处理函数捕获处理；如果在第⼆步构造对象时出现异常，则⾃动调⽤ delete 释放内存。 

执⾏ delete 实际上也有两个过程：

1.使⽤析构函数对对象进⾏析构；

2.回收内存空间（free）。 

以上也可以看出 new 和 malloc 的区别，new 得到的是经过初始化的空间，⽽ malloc 得到的是未初始化的空间。 所以 **new 是 new ⼀个类型，⽽ malloc 则是malloc ⼀个字节⻓度的空间**。

delete 和 free 同理，delete 不仅释放 空间还析构对象，delete ⼀个类型，free ⼀个字节⻓度的空间。 为什么有了 malloc／free 还需要 new／delete？因为对于⾮内部数据类型⽽⾔，光⽤ malloc／free ⽆法满⾜动 态对象的要求。对象在创建的同时需要⾃动执⾏构造函数，对象在消亡以前要⾃动执⾏析构函数。由于 mallo／ free 是库函数⽽不是运算符，**不在编译器控制权限之内**，**不能够把执⾏的构造函数和析构函数的任务强加于 malloc／**free，所以有了 new／delete 操作符。





`new` 和 `malloc` 都是用于动态分配内存的关键字/函数，但它们有几个主要的区别：

1. 语法和类型安全性：`new` 是一个 C++ 关键字，而 `malloc` 是一个 C 标准库函数。因此，使用 `new` 可以直接创建并初始化一个对象，并返回指向该对象的指针。而 `malloc` 只分配一段指定大小的内存空间，并返回一个 `void` 类型的指针。这意味着需要在使用 `malloc` 之后对其返回的指针进行类型转换，并手动调用对象的构造函数。
2. 内存分配大小：`new` 自动计算并分配对象所需的内存大小，而 `malloc` 需要显式指定分配内存的大小，否则可能会导致内存分配失败或溢出。
3. 对象的构造和初始化：`new` 可以自动调用对象的构造函数进行初始化，而 `malloc` 不会执行任何初始化操作，因此需要手动调用构造函数。同样，使用 `delete` 关键字删除对象时，也会自动调用其析构函数来释放资源。而使用 `free` 函数释放 `malloc` 分配的内存时，不会调用对象的析构函数。
4. 返回值：`new` 返回指向已分配的对象的指针，而 `malloc` 返回一个指向已分配内存的 void 指针，需要手动转换为实际的类型指针。

总之，explicit关键字可以避免程序中不必要的隐式类型转换，提高程序的安全性和可读性。在设计类的构造函数时，如果不希望该构造函数被隐式地调用，可以考虑使用explicit关键字。

## 计算机组成原理

#### 虚拟内存和物理内存

物理内存是指计算机中直接可用的内存，也称为实际内存。在操作系统启动时，系统会将物理内存映射到一个连续的地址空间中，并将这个地址空间划分为多个页框，每个页框的大小通常为 4KB 或 8KB 等。程序可以直接访问物理内存，但由于物理内存是有限的，因此当程序需要占用更多的内存时，可能会出现内存不足的情况。

为了解决内存不足的问题，操作系统引入了虚拟内存的概念。虚拟内存是指操作系统中的一个抽象概念，它将程序所需的内存分成多个虚拟地址空间，每个虚拟地址空间都映射到一个物理地址空间中的页框。程序可以访问虚拟内存，而不需要了解物理内存的具体细节。

当程序需要访问虚拟内存中的数据时，操作系统会将相应的虚拟地址映射到物理地址空间中的页框，如果页框已经存在于物理内存中，则直接访问该页框，如果页框不在物理内存中，则操作系统会将该页框从磁盘中读取到物理内存中，并更新页表信息。

虚拟内存和物理内存之间的映射关系由操作系统维护，对程序来说是透明的。虚拟内存可以让程序使用比物理内存更多的内存，但也会增加操作系统的负担，并且由于虚拟内存的访问需要额外的硬件支持，因此访问虚拟内存的速度通常比访问物理内存的速度慢。

## STL

链式序列化容器

1. vector：基于数组实现，使用动态扩展的方式实现自动增长，支持随机访问，但在插入和删除操作中性能较差。
2. deque：双端队列，底层也是基于数组实现，但使用多个连续的内存块来存储数据，支持随机访问和在队列两端的高效插入和删除操作。
3. list：双向链表实现，每个元素包含指向前驱和后继元素的指针，支持在链表中高效的插入和删除操作，但不支持随机访问。
4. forward_list：单向链表实现，与 list 不同的是，每个元素只包含指向后继元素的指针，不包含指向前驱元素的指针。
5. set/map：基于红黑树实现，具有自动排序的特性，支持快速查找、插入和删除操作。
6. unordered_set/unordered_map：基于哈希表实现，使用哈希函数将元素映射到桶中，支持高效的查找、插入和删除操作，但不支持排序。
7. stack：基于 deque 或 list 实现，只支持在栈顶进行插入和删除操作，不支持随机访问。
8. queue：基于 deque 或 list 实现，支持在队列两端进行插入和删除操作，不支持随机访问。
9. priority_queue：基于 vector 实现，使用堆排序算法实现，支持插入和删除操作，并保持队列中的元素始终按照一定的顺序排列。

#### Vector

vector和list的区别，有那些优点和缺点

`vector` is a dynamic array that can grow or shrink in size. It stores its elements in contiguous memory locations and provides fast random access to its elements through its `[]` operator. When the vector grows beyond its current capacity, it reallocates a larger block of memory and moves all of its elements to the new location. This can be an expensive operation, especially for large vectors, but it happens infrequently.

On the other hand, `list` is a doubly linked list, where each element of the list contains a pointer to the previous and next element. Because `list` is implemented as a linked list, it does not provide random access to its elements. To access a specific element in the list, you need to traverse the list from the beginning or end until you find the desired element. However, `list` provides fast insertion and deletion of elements anywhere in the list, as this only involves updating a few pointers.



vector内存分配

`vector`的内存分配过程可以简单地分为两个阶段：分配和构造。

在第一个阶段中，`vector`需要检查它是否有足够的内存容纳新元素。如果没有，`vector`会申请一段更大的内存，并将原始数据复制到新的内存中。这个过程叫做重新分配（re-allocation）。

在第二个阶段中，`vector`需要为新元素分配内存，并在这段内存上构造一个新的元素。这个过程叫做构造（construction）。如果元素是一个类对象，那么就会调用该类对象的构造函数。

当`vector`不再需要一个元素时，它会首先调用该元素的析构函数，然后释放其内存。如果`vector`需要缩小容量，它会将剩余的元素复制到更小的内存中，并释放原始内存。

`vector`通过调用全局操作符`new`和`delete`来分配和释放内存。这些操作符使用堆来分配和释放内存，因此`vector`的内存分配和释放通常比栈上的内存分配和释放更慢。



resize的实现

1. 如果请求的大小小于当前大小，`vector`会销毁多余的元素。如果元素是类对象，那么会调用它们的析构函数。
2. 如果请求的大小大于当前大小，`vector`会重新分配内存以容纳更多的元素。这个过程跟向`vector`中添加元素的过程类似。如果元素是类对象，`vector`会调用它们的默认构造函数来初始化新元素。
3. 如果请求的大小等于当前大小，`vector`不会做任何事情。

元素的引用、指针或迭代器。如果请求的大小小于当前大小，`vector`的复杂度为线性

#### Map unordered_map

map和unordered_map有什么区别

`map`是基于红黑树实现的关联容器，它的特点是键值对按照键的大小进行排序，因此它可以高效地支持有序的键值对访问和查找，但是插入和删除操作的复杂度是对数级别的，因为需要保持树的平衡。

`unordered_map`是基于哈希表实现的关联容器，它的特点是可以高效地支持无序的键值对访问和查找，插入和删除操作的复杂度是常数级别的，因为不需要保持元素的顺序，而且哈希函数的性能通常也比红黑树的查找更快。但是，哈希表有可能会出现哈希冲突，导致查找性能下降，而且无序容器的遍历和排序需要额外的操作。

因此，`map`适合于需要按照键排序的情况，而`unordered_map`适合于需要高效查找、插入和删除元素的情况。需要注意的是，在C++11之前，STL中没有`unordered_map`，而是使用`hash_map`，但是在C++11中已经被废弃了。





hash冲突都怎么解决

解决哈希冲突的方法通常有以下几种：

1. 开放地址法（Open Addressing）：当出现哈希冲突时，该方法会尝试将元素插入到下一个可用的槽中。它包括线性探测、二次探测和双重散列等技术。
2. 链接法（Chaining）：该方法使用链表将所有哈希到同一个槽中的元素组织起来。当哈希冲突发生时，新元素会被插入到链表的头部或尾部。
3. 建立更好的哈希函数：为了减少哈希冲突的发生，可以采用更好的哈希函数，它们能够更好地分布键值对。一些流行的哈希函数包括MurmurHash、CityHash、xxHash等。

#### 线程池

1. 初始化线程池：创建一定数量的线程并启动它们，同时创建一个任务队列，用于存放待执行的任务。
2. 提交任务：将需要执行的任务提交到任务队列中，等待线程池中的线程来执行。
3. 取出任务：线程池中的线程从任务队列中取出任务。
4. 执行任务：线程池中的线程执行任务。
5. 完成任务：任务执行完毕后，线程将结果返回给调用方，或者将结果存储到共享变量中。
6. 重复执行：线程池中的线程将不断循环执行取出任务、执行任务的过程，直到线程池被关闭或者任务队列为空。

`pthread_create` 可以创建线程、通过 `pthread_exit` 可以销毁线程

1. corePoolSize：核心线程数，线程池正常情况下保持的线程数，大户人家“长工”的数量。
2. maximumPoolSize：最大线程数，当线程池繁忙时最多可以拥有的线程数，大户人家“长工”+“短工”的总数量。
3. keepAliveTime：空闲线程存活时间，没有活之后“短工”可以生存的最大时间。
4. TimeUnit：时间单位，配合参数 3 一起使用，用于描述参数 3 的时间单位。
5. BlockingQueue：线程池的任务队列，用于保存线程池待执行任务的容器。
6. ThreadFactory：线程工厂，用于创建线程池中线程的工厂方法，通过它可以设置线程的命名规则、优先级和线程类型。
7. RejectedExecutionHandler：拒绝策略，当任务量超过线程池可以保存的最大任务数时，执行的策略。



多线程的应用场景：

1. 图形用户界面(GUI)应用程序：图形用户界面需要与用户进行交互，而同时也需要在后台处理一些任务，例如文件的读写、网络请求等。使用多线程可以避免界面卡顿，提高用户体验。
2. 数据库应用程序：多个线程可以并发地对数据库进行操作，提高数据的读写效率。
3. Web应用程序：Web服务器需要处理多个请求，使用多线程可以提高服务器的并发处理能力。
4. 计算密集型应用程序：例如图像处理、视频处理、加密解密等，可以将任务分割成多个子任务，并行处理，提高计算效率。

多进程的应用场景：

1. 计算密集型应用程序：与多线程类似，但是多进程可以更好地利用多核CPU的性能。
2. 网络服务器应用程序：可以将不同的请求分配给不同的进程进行处理，提高服务器的并发处理能力。
3. 安全性要求高的应用程序：不同的进程之间可以使用IPC(Inter-process communication)进行通信，但是彼此之间是独立的，可以提高应用程序的安全性。
4. 处理IO密集型任务：例如文件的读写、网络请求等，使用多进程可以避免IO操作的阻塞，提高处理效率。

## TCP编程

#### IO复⽤的原理？零拷⻉？三个函数？epoll 的 LT 和 ET 模式的理解

1) IO复⽤是Linux中的IO模型之⼀，IO复⽤就是进程预先告诉内核需要监视的IO条件，使得内核⼀旦发现进程指定 的⼀个或多个IO条件就绪，就通过进程进程处理，从⽽不会在单个IO上阻塞了。Linux中，提供了select、poll、 epoll三种接⼝函数来实现IO复⽤。 

2) Select的缺点： 

① 单个进程能够监视的⽂件描述符的数ᰁ存在最⼤限制，通常是1024。由于select采⽤轮询的⽅式扫描⽂件描述 符，⽂件描述符数ᰁ越多，性能越差； 

② 内核/⽤户空间内存拷⻉问题，select需要⼤ᰁ句柄数据结构，产⽣巨⼤开销； 

③ Select返回的是含有整个句柄的数组，应⽤程序需要遍历整个数组才能发现哪些句柄发⽣事件； 

④ Select的触发⽅式是⽔平触发，应⽤程序如果没有完成对⼀个已经就绪的⽂件描述符进⾏IO操作，那么每次 select调⽤还会将这些⽂件描述符通知进程。 



3) Poll 与select相⽐，poll使⽤链表保存⽂件描述符，⼀你才没有了监视⽂件数ᰁ的限制，但其他三个缺点依然存在 

4) **Epoll 上⾯所说的select缺点在epoll上不复存在，epoll使⽤⼀个⽂件描述符管理多个描述符，将⽤户关系的⽂件描述符的 事件存放到内核的⼀个事件表中，这样在⽤户空间和内核空间的copy只需⼀次。Epoll是事件触发的，不是轮询查 询的。没有最⼤的并发连接限制，内存拷⻉，利⽤mmap（）⽂件映射内存加速与内核空间的消息传递。** 

区别总结： 

1) ⽀持⼀个进程所能打开的最⼤连接数 

① Select最⼤1024个连接，最⼤连接数有FD_SETSIZE宏定义，其⼤⼩是32位整数表示，可以改变宏定义进⾏修 改，可以᯿新编译内核，性能可能会影响； 

② Poll没有最⼤连接限制，原因是它是基于链表来存储的； 

③ 连接数限数有上限，但是很⼤； 

2) FD剧增后带来的IO效率问题 

① 因为每次进⾏线性遍历，所以随着FD的增加会造成遍历速度下降，效率降低； 

② Poll同上；

 ③ 因为epool内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调⽤callback，所以 在活跃socket较少的情况下，使⽤epoll没有前⾯两者的现象下降的性能问题。 



3) 消息传递⽅式 ① Select内核需要将消息传递到⽤户空间，都需要内核拷⻉； 

② Poll同上；

 ③ Epoll通过内核和⽤户空间共享来实现的。 





epoll 的 LT 和 ET 模式的理解： epoll对⽂件描述符的操作有两种模式：LT(level trigger)和ET(edge trigger)，LT是默认模式。 



区别： 

LT模式：当epoll_wait检测到描述符事件发⽣并将此事件通知应⽤程序，应⽤程序可以不⽴即处理该事件。下次调⽤epoll_wait时，会再次响应应⽤程序并通知此事件。 

ET模式：当epoll_wait检测到描述符事件发⽣并将此事件通知应⽤程序，应⽤程序必须⽴即处理该事件。如果不处 理，下次调⽤epoll_wait时，不会再次响应应⽤程序并通知此事件。 



在 select/poll中，进程只有在调⽤⼀定⽅法后，内核才对所有监视的⽂件描述符进⾏扫描，⽽epoll事先通过 epoll_ctl()来注册⼀个⽂件描述符，⼀旦某个⽂件描述符就绪时，内核会采⽤类似callback的回调机制，迅速激活这个⽂件描述符，当进程调⽤epoll_wait时便得到通知（此处去掉了遍历⽂件描述符，⽽是通过监听回调的机制，这 也是epoll的魅⼒所在）。 Epoll 的优点主要体现咋如下⼏个⽅⾯： 1. 监视的描述符不受限制，它所⽀持的FD上限是最⼤可以打开⽂件的数⽬，这个数字⼀般远⼤于2048，举个栗 ⼦，具体数⽬可以在cat/proc/sys/fs/file-max 查看，⼀般来说，这个数⽬和内存关系很⼤。 2. Select最⼤的缺点是进程打开的fd数⽬是有限制的，这对于连接数⽬较⼤的服务器来说根本不能满⾜，虽然也 可以选择多进程的解决⽅案（Apache就是如此）；不过虽然linux上⾯创建进程的代价较⼩，但仍旧不可忽 视，加上进程间数据同步远⽐不上线程间同步⾼效，所以并不是⼀种完美的解决⽅案。 3. IO的效率不会随着监视fd的数ᰁ的增⻓⽽下降，epoll不同于select和poll的轮询⽅式，⽽是通过每个fd定义的 回调函数来实现，只有就绪的fd才会执⾏回调函数。 4. 如果没有⼤ᰁ的idle -connection或者dead-connection，epoll的效率并不会⽐select/poll⾼很多，但是当遇 到⼤ᰁ的idle- connection，就会发现epoll的效率⼤⼤⾼于select/poll。



这是由于我们在调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。

 

这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。

#### epoll底层实现

https://www.cnblogs.com/charlesblc/p/6242479.html

`epoll` 是 Linux 内核提供的一种 I/O 事件通知机制，相比较于传统的 `select/poll`，`epoll` 可以更加高效地处理大量并发连接。下面是 `epoll` 的底层实现原理：

1. `epoll` 将需要监听的文件描述符放入一个红黑树中，以文件描述符为 key，每个文件描述符对应一个节点。而 `select/poll` 则需要将所有的文件描述符放在一个数据结构中，遍历所有的文件描述符来查找事件。
2. `epoll` 使用一个双向链表来存储发生事件的文件描述符。这个链表的头节点可以通过 `epoll_create()` 系统调用获得。每个节点中保存了发生事件的文件描述符、事件类型等信息。
3. 当一个文件描述符上有事件发生时，内核会遍历红黑树中的节点，找到对应的文件描述符节点，将该节点加入到双向链表中。如果节点已经在链表中，则不做处理。这个过程中，只需要遍历少量的节点，而不是全部文件描述符，因此效率更高。
4. 用户可以通过 `epoll_wait()` 系统调用获取发生事件的文件描述符。这个系统调用会阻塞等待事件的发生。当事件发生时，内核会将发生事件的文件描述符从双向链表中移除，并将文件描述符和事件类型等信息拷贝到用户空间中，然后返回给用户进程。

总之，`epoll` 利用红黑树和双向链表来管理需要监听的文件描述符，避免了遍历所有文件描述符的开销，并且在事件发生时能够快速地找到对应的文件描述符节点。这使得 `epoll` 相比于 `select/poll` 更加高效。

将事件的注册和等待返回分开是一种常见的做法，可以方便地将多个 socket 注册到同一个 `epoll` 实例中，而不需要将每个 socket 都添加到一个等待返回的 `epoll_wait` 中。这样，我们可以在 `epoll` 实例中维护多个 socket，而只需等待实例返回事件。

#### 常⻅的IO模型，五种？异步IO应⽤场景？有什么缺点？

1) 同步 就是在发出⼀个功能调⽤时，在没有得到结果之前，该调⽤就不返回。*也就是必须⼀件⼀件事做*,等前⼀件做完 了才能做下⼀件事。就是我调⽤⼀个功能，该功能没有结束前，我死等结果。 

2) 异步 当⼀个异步过程调⽤发出后，调⽤者不能⽴刻得到结果。实际处理这个调⽤的部件在完成后，通过状态、通知和回 调来通知调⽤者。就是我调⽤⼀个功能，不需要知道该功能结果，该功能有结果后通知我（回调通知） 

3) 阻塞 阻塞调⽤是指调⽤结果返回之前，当前线程会被挂起（线程进⼊⾮可执⾏状态，在这个状态下，cpu不会给线程分 配时间⽚，即线程暂停运⾏）。函数只有在得到结果之后才会返回。对于同步调⽤来说，很多时候当前线程还是激 活的，只是从逻辑上当前函数没有返回⽽已。 就是调⽤我（函数），我（函数）没有接收完数据或者没有得到结果 之前，我不会返回。 

4) ⾮阻塞 指在不能⽴刻得到结果之前，该函数不会阻塞当前线程，⽽会⽴刻返回。就是调⽤我（函数），我（函数）⽴即返 回，通过select通知调⽤者。 



**1) 阻塞I/O** 应⽤程序调⽤⼀个IO函数，导致应⽤程序阻塞，等待数据准备好。 如果数据没有准备好，⼀直等待….数据准备好 了，从内核拷⻉到⽤户空间,IO函数返回成功指示。 



**2) ⾮阻塞I/O** 我们把⼀个SOCKET接⼝设置为⾮阻塞就是告诉内核，当所请求的I/O操作⽆法完成时，不要将进程睡眠，⽽是返回 ⼀个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准 备好为⽌。在这个不断测试的过程中，会⼤ᰁ的占⽤CPU的时间。 



**3) I/O复⽤** I/O复⽤模型会⽤到select、poll、epoll函数，**这⼏个函数也会使进程阻塞**，但是和阻塞I/O所不同的的，**这三个函 数可以同时阻塞多个I/O操作。⽽且可以同时对多个读操作，多个写操作的I/O函数进⾏检测**，直到有数据可读或可 写时，才真正调⽤I/O操作函数。 



**4) 信号驱动I/O** ⾸先我们允许套接⼝进⾏信号驱动I/O,并安装⼀个信号处理函数，进程继续运⾏并不阻塞。当数据准备好时，**进程 会收到⼀个SIGIO信号，可以在信号处理函数中调⽤I/O操作函数处理数据。** 



**5) 异步I/O** 当⼀个异步过程调⽤发出后，调⽤者不能⽴刻得到结果。实际处理这个调⽤的部件在完成后，通过状态、通知和回 调来通知调⽤者的输⼊输出操作。

#### 零拷贝技术

零拷贝技术（Zero-copy）是一种计算机内存管理技术，它可以通过避免数据在内存中的多次复制而提高数据传输的效率。在传统的数据传输方式中，当一个进程想要将数据从一个应用程序发送到另一个应用程序时，数据必须先被复制到内核缓冲区，然后再从内核缓冲区复制到目标进程的用户空间缓冲区中。这样的多次数据复制会带来性能瓶颈，尤其是在高速网络环境下，会浪费大量的 CPU 时间和内存带宽。

零拷贝技术的实现方式是通过使用 DMA（Direct Memory Access）引擎或专用的网络卡硬件来直接访问应用程序缓冲区中的数据，然后将数据直接发送到网络中或者接收网络数据并直接写入到应用程序缓冲区中，而无需将数据复制到内核缓冲区。这样可以避免数据在内存中的多次复制，从而提高了数据传输的效率。

零拷贝技术可以广泛应用于网络数据传输、磁盘 I/O 等场景中，可以提高数据传输的效率，减少 CPU 和内存的开销，从而提高系统的整体性能。

使用 mmap() 系统调用也可以实现零拷贝技术。在使用 mmap() 系统调用时，可以将文件映射到进程的虚拟内存空间中，并直接读取或写入文件内容。这样可以避免将数据复制到内核缓冲区或用户空间缓冲区中，从而提高数据传输的效率。

## 算法题

程序题：（面试官没调好，没做成）

后序遍历

leetcode151反转字符串单词的升级版，会有不是字母的情况。没写出来，但是思路还是有点，15分钟太少了，整理一下思路就基本没啥时间了，太菜了，而且也忘了字符转ASCII码的那个函数是啥了（ord/chr），寄

#### 排序

堆排序（Heap Sort）：

- 时间复杂度：O(nlogn+n) 建堆
- 空间复杂度：O(1)

快速排序（Quick Sort）：

- 时间复杂度：O(nlogn)（期望情况），O(n^2)（最坏情况）
- 空间复杂度：O(logn)

归并排序（Merge Sort）：

- 时间复杂度：O(nlogn)
- 空间复杂度：O(n)

快排，找pivot，然后根据大小，交换元素

1. 冒泡排序（Bubble Sort）、插入排序（Insertion Sort）、归并排序（Merge Sort）、计数排序（Counting Sort）和基数排序（Radix Sort）是稳定的排序算法。
2. 快速排序（Quick Sort）、希尔排序（Shell Sort）、选择排序（Selection Sort）和堆排序（Heap Sort）是不稳定的排序算法。

##### 查找次数

假设顺序表中有 n 个元素，查找成功的平均长度指的是平均需要比较多少个元素才能找到目标元素。

如果顺序表中的元素是随机排列的，那么查找成功的平均长度为 (n+1)/2，即顺序表长度的一半再加一。这是因为，在随机情况下，每个元素被查找到的概率相等，因此平均需要比较的元素个数是所有元素位置的平均值，即：

(1+2+...+n)/n = (n+1)/2

## 项目

### tinySTL

**预处理指令** #pragma once 防止头文件重复引用



一字节对齐

### webserver

http1.1和1.0有什么区别

cache control字段

##### bind绑定端口

在服务端，如果不调用 bind 函数绑定一个端口号，那么内核会自动为该服务分配一个随机的端口号。这样，客户端就无法事先知道服务端的端口号，需要在连接时动态获取。如果服务端需要暴露给外部的端口号不确定或需要保持一致，那么就需要显式地调用 bind 函数指定端口号。

在客户端，通常不需要显式地调用 bind 函数绑定端口号。如果调用 bind 函数指定一个端口号，那么客户端就会使用该端口号进行通信，这可能会影响到客户端与服务端的通信效率。因此，在客户端一般不需要显式地调用 bind 函数。



服务器

创建socket -> int socket(int domain, int type, int protocol)

绑定socket和端⼝号 -> int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen)

监听端⼝号 -> int listen(int sockfd, int backlog)

接收⽤户请求 -> int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen)

从socket中读取字符 -> ssize_t read(int fd, void *buf, size_t count)

关闭socket -> int close(int fd)

客户端

创建socket -> int socket(int domain, int type, int protocol);

连接指定计算机 -> int connect(int sockfd, struct sockaddr* addr, socklen_t addrlen);

向socket写⼊信息 -> ssize_t write(int fd, const void *buf, size_t count);

关闭oscket -> int close(int fd);

#### proactor模式

Proactor 模式是一种高效的异步 I/O 模型，它属于 Reactor 模式的变种。在 Proactor 模式中，当一个 I/O 操作完成后，操作的结果会被封装成一个事件，然后通过操作系统的异步通知机制通知应用程序。应用程序通过事件处理器处理这个事件，从而完成 I/O 操作。

Proactor 模式相对于 Reactor 模式的优势在于，在 I/O 操作执行期间，操作系统会负责将数据从内核空间复制到用户空间，从而减少了用户空间和内核空间之间的数据拷贝操作，提高了 I/O 操作的效率。同时，Proactor 模式也能够充分利用操作系统的异步通知机制，减少了用户空间和内核空间之间的切换次数，提高了应用程序的并发处理能力。

在 Proactor 模式中，应用程序需要将 I/O 操作的完成事件与相应的处理器关联起来，这个关联关系可以通过事件处理器的注册来实现。当 I/O 操作完成后，操作系统会通知应用程序相关的事件处理器，然后应用程序就可以在事件处理器中获取到 I/O 操作的结果，并进行相应的处理。

Proactor 模式适用于高并发、高吞吐量的应用程序场景，例如网络服务器、数据库系统等。常见的 Proactor 实现包括 Windows 的 I/O Completion Port 和 Linux 的 AIO (Asynchronous I/O) 等。

#### websocket和socket

1. Socket Socket是一种面向流的网络通信协议，主要用于实现客户端和服务端之间的数据传输。它基于传输控制协议TCP或用户数据报协议UDP，能够实现可靠的数据传输，但需要应用程序自己实现消息分包、粘包等处理。Socket通信一般需要编写底层网络通信代码，实现细节较多，使用起来较为复杂。
2. WebSocket WebSocket是一种全双工的网络通信协议，基于HTTP协议，通过在HTTP握手阶段升级协议，从而实现长连接。WebSocket能够实现服务器主动向客户端推送数据，而不需要客户端发送请求，从而节省网络带宽和服务器资源。同时，WebSocket协议支持二进制和文本数据传输，能够实现更加灵活和高效的数据交互。WebSocket通信相对于Socket通信来说，使用起来更加简单，但需要服务端和客户端都支持WebSocket协议。
3. `websocket` 用的是 `TCP` 还是`UDP`

> WebSocket是基于TCP协议的

#### thrift的接口

1. Synchronous接口 Synchronous接口是最基本的接口类型，它是一种阻塞式调用方式，即客户端发起请求后需要等待服务端响应返回结果。这种接口适用于对服务响应速度不敏感的场景。
2. Asynchronous接口 Asynchronous接口是一种非阻塞式调用方式，即客户端发起请求后可以继续执行其他任务，服务端响应返回结果后再通知客户端。这种接口适用于对服务响应速度较为敏感的场景。
3. One-way接口 One-way接口是一种单向调用方式，即客户端发送请求后不需要等待服务端响应，而是直接继续执行后续任务。这种接口适用于对响应结果不关心的场景，例如日志记录等。
4. Callback接口 Callback接口是一种回调式调用方式，即客户端发送请求后服务端将结果通过回调函数的方式通知客户端。这种接口适用于对服务端主动推送结果的场景，例如消息推送等。

#### 设计的游戏引擎

动态刷新，

粒子效果：往外散射，每一个角度都往外散射粒子

碰撞：两个球碰到了之后都会往后弹，然后会减速

随机发射炮弹

#### Oauth2

OAuth 2.0是一种授权框架，用于在不泄露用户凭据的情况下授权第三方应用程序访问受保护的资源。它允许用户在不与第三方共享他们的用户名和密码的情况下，授权第三方应用程序访问他们的受保护资源。OAuth 2.0由一组角色、授权流和令牌组成，包括以下几个组成部分：

1. 授权服务器(Authorization Server)：验证并授权第三方应用程序的请求，然后向应用程序发放访问令牌(Access Token)。
2. 资源服务器(Resource Server)：存储受保护的资源，并且仅当受到有效令牌的请求时才提供对资源的访问。
3. 第三方应用程序(Client)：向授权服务器请求访问令牌，并使用该令牌向资源服务器请求受保护资源。
4. 资源拥有者(Resource Owner)：拥有访问受保护资源的用户，可以授权第三方应用程序访问他们的资源。

OAuth 2.0定义了四种授权流程：

1. 授权码模式(Authorization Code Grant)：适用于Web应用程序和移动应用程序，它允许第三方应用程序通过重定向用户的浏览器来获取授权码(Authorization Code)，然后使用该授权码向授权服务器请求访问令牌。
2. 简化模式(Implicit Grant)：适用于Web应用程序和移动应用程序，它允许第三方应用程序在不涉及授权码的情况下向授权服务器请求访问令牌。
3. 密码模式(Resource Owner Password Credentials Grant)：适用于受信任的第一方应用程序，它允许第三方应用程序使用资源拥有者的用户名和密码来请求访问令牌。
4. 客户端凭证模式(Client Credentials Grant)：适用于机器到机器通信的场景，它允许第三方应用程序使用客户端ID和客户端秘钥来请求访问令牌。

OAuth 2.0提供了一个灵活而安全的机制，允许用户授权第三方应用程序访问他们的资源，同时不需要共享他们的凭据。它是一种非常流行的授权框架，广泛应用于Web应用程序和移动应用程序的开发中。



#### 你来设计一个网络库，你会怎么设计？（不知道，遵循Ractor模型？）

设计一个网络库需要考虑多个方面，包括接口设计、协议支持、网络通信、多线程处理、错误处理等。下面是一个简单的网络库设计方案，供参考：

1. 接口设计
   - 应该提供简单易用的接口，包括创建和销毁网络连接、发送和接收数据等操作。
   - 应该支持同步和异步操作两种模式，并提供相应的回调函数。
   - 应该支持不同的协议，例如 TCP、UDP、HTTP 等。
   - 应该提供网络事件通知机制，例如连接建立和关闭、数据接收和发送等事件。
2. 协议支持
   - 应该支持常见的协议，例如 TCP、UDP、HTTP、WebSocket 等。
   - 应该提供相应的协议解析器，能够解析协议头和数据，并提供相应的回调函数。
   - 应该支持自定义协议，能够灵活适应不同的应用场景。
3. 网络通信
   - 应该使用非阻塞 IO 模型，能够处理大量并发连接。
   - 应该使用 IO 多路复用技术，例如 select、poll、epoll 等，提高网络通信效率。
   - 应该支持数据加密和压缩等功能，提高数据传输安全性和效率。
4. 多线程处理
   - 应该使用线程池技术，避免频繁地创建和销毁线程。
   - 应该使用任务队列，将网络事件和数据处理任务提交到任务队列中，由线程池处理。
5. 错误处理
   - 应该提供错误处理机制，能够捕获和处理网络异常和错误。
   - 应该提供日志记录功能，便于调试和排查错误。

以上是一个简单的网络库设计方案，实际设计中需要根据具体应用场景进行调整和优化。同时，在设计网络库时还需要考虑网络安全、性能优化、代码可读性等方面的问题。



7 还问了我为什么不用cookie，没答上来，我只能回答一下cookie 和 session的区别

8 项目中中间件是怎么用的，回答就是用Django自带的MiddlewareMixin类做的，感觉还要再了解一下中间件

9 简单介绍一下Django框架，回答是MVC和ORM



我回答登录模块的实现（session 中间件 验证码）





## 计算机网络

#### Keep alive

TCP和HTTP中的Keep-Alive字段都是用来优化网络性能的。下面分别介绍一下它们的作用：

1. TCP中的Keep-Alive

TCP协议是面向连接的，建立连接需要经过三次握手，断开连接需要经过四次握手。如果在一个HTTP事务中需要多次请求，则每次都需要建立和断开TCP连接，这样会带来额外的开销和延迟。

TCP协议中的Keep-Alive机制可以在两次请求之间保持TCP连接的状态，避免了建立和断开连接的开销，减少了延迟和资源的消耗。当客户端和服务器之间的一次TCP连接中完成了一个HTTP事务，但TCP连接仍然保持打开状态，可以被重复利用，这种保持连接的机制就是TCP Keep-Alive。

在TCP Keep-Alive机制中，客户端向服务器发送一个Keep-Alive消息，服务器收到后会返回一个相应的消息，以此保持连接的状态。如果一定时间内没有数据传输，则连接会被自动关闭。这个时间间隔可以通过修改TCP的Keep-Alive定时器的值来调整。

1. HTTP中的Keep-Alive

在HTTP/1.0中，每个请求都需要重新建立TCP连接，这样会增加很多额外的开销和延迟。为了解决这个问题，HTTP/1.1引入了Keep-Alive机制，可以在一个TCP连接上进行多次请求和响应，避免了建立和断开连接的开销。

在HTTP/1.1中，默认情况下是开启Keep-Alive的，如果服务器不想保持连接，则需要在响应头中指定Connection: close字段来关闭Keep-Alive。

HTTP中的Keep-Alive机制可以减少网络传输的开销，提高网络性能，但也需要注意保持连接时间过长会占用服务器资源。因此，在实际应用中需要根据具体的场景来调整Keep-Alive的参数。

TCP中的Keep-Alive机制是通过发送心跳包来判断连接是否断开，从而保持TCP连接的状态。当一端长时间未收到另一端的数据时，就会发送心跳包，如果连续发送几次都没有收到回复，则认为连接已经断开。

#### 状态码

1xx（信息性状态码）：请求已被服务器接收，继续处理中。

- 100（继续）：服务器收到请求，需要客户端继续发送请求的其余部分。

2xx（成功状态码）：请求已成功处理完毕。

- 200（成功）：请求已成功处理。

3xx（重定向状态码）：需要客户端采取进一步的操作才能完成请求。

- 301（永久重定向）：请求的资源已经被永久移动到新 URI，返回信息中包含新的 URI。
- 302（临时重定向）：请求的资源已经被临时移动到新 URI，返回信息中包含新的 URI。

4xx（客户端错误状态码）：客户端的请求有错误，常见的有“未授权”、“禁止访问”、“请求不存在”等。

- 400（错误请求）：请求中存在语法错误或无法满足请求。
- 401（未授权）：请求需要身份验证。
- 403（禁止访问）：服务器拒绝请求。
- 404（未找到）：请求的资源不存在。

5xx（服务器错误状态码）：服务器未能完成请求，常见的有“服务器内部错误”、“服务器过载”等。

- 500（服务器内部错误）：服务器遇到了一个未曾预料的状况，导致无法完成客户端的请求。
- 502（错误网关）：服务器作为网关或代理，从上游服务器接收到了一个无效的响应。
- 503（服务不可用）：服务器暂时处于过载或维护状态

#### HTTP

HTTP（HyperText Transfer Protocol）是一种用于传输超文本的协议，是 Web 浏览器和 Web 服务器之间通信的基础。HTTP是一个无状态协议，即每个请求都是相互独立的，服务器不会保存任何客户端请求的信息。HTTP基于请求/响应模型，客户端发送请求给服务器，服务器返回响应。

HTTP协议的请求和响应消息都包含三个部分：起始行、首部和主体。起始行包含请求方法或响应状态码、URI和HTTP版本号；首部包含一些附加信息，如Cookies、请求的MIME类型、响应的Content-Type等；主体包含实际的数据内容，如网页的HTML文档。

此外，HTTP还有一些相关的协议和标准，如

HTTPS（HTTP over SSL/TLS），REST（Representational State Transfer，一种基于HTTP协议的软件架构风格）

#### HTTP1.0和1.1

1. 持久连接

HTTP 1.0中，默认情况下每个请求/响应都需要建立新的连接。这会导致性能问题，因为在每个请求/响应之间建立连接会浪费时间和资源。在HTTP 1.1中，使用持久连接可以在单个连接上发送多个请求/响应，从而减少了网络延迟和服务器负担。

2. 分块传输编码

在HTTP 1.0中，服务器无法将响应拆分为多个部分进行传输。这意味着客户端必须等待服务器完成整个响应才能开始处理它。在HTTP 1.1中，使用分块传输编码可以在传输期间将响应拆分为多个部分。这意味着客户端可以更早地开始处理响应，从而提高了性能。

3. **请求管线化**

在HTTP 1.0中，请求管线化不是强制要求的。这意味着客户端只能在接收到前一个请求的响应后才能发送下一个请求。在HTTP 1.1中，请求管线化是默认启用的。这意味着客户端可以同时发送多个请求，而无需等待前一个请求的响应。

4. 缓存处理

在HTTP 1.0中，缓存处理不是强制要求的。这意味着服务器无法告诉客户端如何缓存响应。在HTTP 1.1中，服务器可以使用Cache-Control响应头来告诉客户端如何缓存响应。这可以减少对服务器的请求，从而提高性能。

```txt
public：响应可以被任何对象（包括客户端和代理服务器）缓存。

private：响应只能被单个用户缓存，不能被共享缓存（例如代理服务器）缓存。

no-cache：客户端和缓存服务器不能缓存响应，每次都必须重新获取响应。

no-store：客户端和缓存服务器不能缓存响应，并且不允许将响应保存在任何持久化存储中（例如硬盘）。no-cache和no-store指令之间的主要区别在于，no-cache指令仍然允许缓存，但缓存服务器必须在每次请求时重新验证响应的有效性，而no-store指令完全禁止任何形式的缓存。

must-revalidate：客户端和缓存服务器必须在使用缓存响应之前验证响应的有效性。如果响应过期或被修改，则必须从服务器获取新的响应。

max-age：指定响应在被缓存之前可以被保持的时间长度（以秒为单位）。

s-maxage：类似于max-age，但只适用于共享缓存（例如代理服务器），而不适用于客户端缓存。

no-transform：禁止代理服务器修改响应的媒体类型或编码。

immutable：响应内容是不可变的，即使缓存已过期，也不能从源服务器重新获取新的响应。
```

5. Host头部

在HTTP 1.0中，每个请求都需要使用完整的URL来标识服务器上的资源。在HTTP 1.1中，使用Host头部可以在单个IP地址上托管多个域名。这使得共享主机变得更加容易。

#### http和https的区别？

HTTP（HyperText Transfer Protocol）是一种用于传输超文本的协议，它是基于**TCP/IP协议**的应用层协议。它的主要特点是简单、快速，但是传输的数据是明文的，容易被窃听、篡改和劫持。因此，HTTP通常不适用于对数据安全性要求较高的场景，如网上银行、电子商务等。

HTTPS（HyperText Transfer Protocol Secure）是基于HTTP协议，**通过SSL或TLS加密协议来保证数据**的安全传输。HTTPS的加密方式采用**公钥加密和私钥解密**的方式，使用SSL证书来验证服务器的身份，可以保证传输的数据不被篡改、窃取或者伪造。因此，HTTPS适用于对数据安全性要求较高的场景，如网上银行、电子商务等。

数据加密、身份认证、数据完整性（integrity）

**具体来说，HTTP和HTTPS的区别有以下几个方面：**

1. **安全性：HTTPS比HTTP更安全，能够防止数据被窃听、篡改和伪造。**
2. **加密方式：HTTPS使用SSL或TLS加密协议，HTTP没有加密。**
3. **端口号：HTTP默认端口号是80，HTTPS默认端口号是443。**
4. **速度：由于HTTPS需要进行加密和解密操作，因此比HTTP的传输速度慢一些。**

总之，如果涉及到敏感信息的传输，比如用户名、密码等，应该使用HTTPS协议来保证数据的安全性。

#### HTTPS具体实现

HTTPS的加密过程主要包括以下几个步骤：

1. 客户端发送请求：客户端向服务器发送HTTPS请求。
2. 服务器响应：服务器返回数字证书。
3. 客户端验证证书：客户端验证服务器的数字证书是否合法，包括证书的颁发机构、证书的有效期等等。
4. 生成对称密钥：客户端使用服务器的公钥加密随机生成的对称密钥，并将加密后的密钥发送给服务器。
5. 传输加密：客户端和服务器使用协商好的对称密钥进行数据加密和解密。
6. 完成握手：握手成功后，客户端和服务器开始进行加密通信。

在以上过程中，数字证书起到了关键的作用，数字证书用于证明服务器的身份和加密数据的公钥。数字证书由数字证书颁发机构（CA）颁发，包含服务器的公钥、服务器的名称、颁发机构的名称等信息。在HTTPS握手过程中，客户端会验证服务器返回的数字证书是否有效，如果数字证书有效，则客户端会生成随机的对称密钥并使用服务器的公钥加密发送给服务器，确保数据的安全性。

总之，HTTPS通过使用TLS/SSL协议对HTTP数据进行加密、身份认证和数据完整性保护，确保数据在传输过程中的安全性和保密性。数字证书则用于验证服务器的身份和加密数据的公钥，保证通信双方的真实身份。

#### OSI七层模型？TCP/IP四层模型？五层协议？

物理层，链路层，网络层，传输层，会话层，表示层，应用层

1. TCP/IP四层模型

- 应用层（Application Layer）
- 传输层（Transport Layer）
- 网络层（Network Layer）
- 链路层（Link Layer）

五层协议

- 应用层（Application Layer）（表示层，会话层）
- 传输层（Transport Layer）
- 网络层（Network Layer）
- 数据链路层（Data Link Layer）分为数据链路层和物理层两层
- 物理层（Physical Layer）

#### TCP如何提供可靠数据传输的？ 

建⽴连接（标志位）：通信前确认通信实体存在。 

序号机制（序号、确认号）：确保了数据是按序、完整到达。

数据校验（校验和）：CRC校验全部数据。 

超时重传（定时器）：保证因链路故障未能到达数据能够被多次重发。 

窗⼝机制（窗⼝）：提供流量控制，避免过量发送。 

拥塞控制：同上。

#### 如何区分流量控制和拥塞控制？

 流量控制属于通信双⽅协商；拥塞控制涉及通信链路全局。 流ᰁ控制需要通信双⽅各维护⼀个发送窗、⼀个接收窗，对任意⼀⽅，接收窗⼤⼩由⾃身决定，发送窗⼤⼩由 接收⽅响应的TCP报⽂段中窗⼝值确定；拥塞控制的拥塞窗⼝⼤⼩变化由试探性发送⼀定数据ᰁ数据探查⽹络 状况后⽽⾃适应调整。 实际最终发送窗⼝ = min{流控发送窗⼝，拥塞窗⼝}。

TCP 主要通过四个算法来进行拥塞控制：

**慢开始、拥塞避免、快重传、快恢复。**

#### tcp和udp有什么区别，应用场景

可以共存，端口是不一样的

TCP（传输控制协议）和UDP（用户数据报协议）是两种不同的网络传输协议，它们有以下几个区别和应用场景：

1. 连接性：TCP 是面向连接的协议，UDP 是无连接的协议。TCP 通过三次握手建立连接，传输数据之前必须要建立连接，而 UDP 不需要建立连接就可以直接传输数据。
2. 可靠性：TCP 提供可靠的数据传输服务，确保数据不会丢失和损坏。TCP 的可靠性是通过数据包确认机制、超时重传机制和流量控制来保证的。而 UDP 没有提供可靠性保证，它只是尽可能快地传输数据，并且不保证数据包的顺序和完整性。
3. 传输速度：UDP 比 TCP 更快，因为它没有 TCP 那样的握手和确认机制，并且没有流量控制，因此它可以尽可能快地传输数据。但是，由于 UDP 不提供可靠性保证，因此数据的传输过程中可能会丢失或损坏。
4. 应用场景：TCP 适合于对可靠性和有序性要求较高的应用，例如 HTTP、FTP 等应用；而 UDP 适合于对传输速度和实时性要求较高的应用，例如视频流、语音通话等应用。

#### TCP和udp有那些应用层协议

常见的基于 TCP 协议的应用层协议有：

1. HTTP：超文本传输协议，用于 Web 应用程序之间的数据传输。
2. FTP：文件传输协议，用于文件传输和管理。
3. SMTP：简单邮件传输协议，用于电子邮件的传输。
4. Telnet：远程终端协议，用于远程控制计算机或网络设备。
5. SSH：安全外壳协议，用于安全地远程访问计算机或网络设备。

常见的基于 UDP 协议的应用层协议有：

1. DNS：域名系统，用于将域名解析为 IP 地址。
2. DHCP：动态主机配置协议，用于自动配置 IP 地址、子网掩码等网络参数。
3. TFTP：简单文件传输协议，用于在网络上进行简单的文件传输。
4. SNMP：简单网络管理协议，用于远程管理网络设备。

#### TCP三次握手四次挥手

- 第⼀次：客户端发含SYN位，SEQ_NUM = S的包到服务器。（客 -> SYN_SEND） 
- 第⼆次：服务器发含ACK，SYN位且ACK_NUM = S + 1，SEQ_NUM = P的包到客户机。（服 -> SYN_RECV）
-  第三次：客户机发送含ACK位，**ACK_NUM = P + 1**的包到服务器。（客 -> ESTABLISH，服 -> ESTABLISH）第三次可以携带数据

接下来，以三个方面分析三次握手的原因：

- 三次握手才可以阻止重复历史连接的初始化（主要原因）

- 三次握手才可以同步双方的初始序列号

  四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

  而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

- 三次握手才可以避免资源浪费

  如果只有「两次握手」，当客户端发生的 `SYN` 报文在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，**由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 `ACK` 报文，所以服务端每收到一个 `SYN` 就只能先主动建立一个连接**，这会造成什么情况呢？

  如果客户端发送的 `SYN` 报文在网络中阻塞了，重复发送多次 `SYN` 报文，那么服务端在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

  我这里两次握手是假设「由于没有第三次握手，服务端不清楚客户端是否收到了自己发送的建立连接的 `ACK` 确认报文，所以每收到一个 `SYN` 就只能先主动建立一个连接」这个场景。

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。



#### 建立的时候握手断开了怎么办

##### 第一次握手丢失了，会发生什么？

当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 `SYN_SENT` 状态。

在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。

##### 第二次握手丢了

因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是**客户端就会触发超时重传机制，重传 SYN 报文**。

然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。

那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。

##### 第三次握手丢失

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

注意，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。

#### 四次挥手

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

你可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

在挥手过程中，每个节点必须维护一个定时器，如果在一段时间内没有收到对方的回复，则重新发送报文。为了保证挥手的正确性，TCP协议规定，收到FIN报文后，需要等待2倍的最大报文段生存时间（MSL）才能关闭连接。

MSL是指TCP报文在网络中的最长生存时间，它的值通常为2分钟。MSL的目的是确保网络中所有的数据包都能够被完全接收或丢弃，避免数据包在网络中无限期地循环，导致网络拥堵或其他问题。

因此，挥手中需要等待2倍的MSL的时间，是为了确保网络中的所有数据包都能够被完全接收或丢弃，避免数据包在网络中无限期地循环。这样可以保证连接的可靠关闭。

- TIME_WAIT 是主动关闭链接时形成的，等待`2MSL`时间，约 44 分钟。主要是防止最后一个`ACK`丢失。 由于`TIME_WAIT` 的时间会非常长，因此server端应尽量减少主动关闭连接
- CLOSE_WAIT：（假设服务器）接收到客户机FIN包之后等待关闭的阶段。在接收到对⽅的FIN包之后， ⾃然是需要⽴即回复ACK包的，表示已经知道断开请求。但是本⽅是否⽴即断开连接（发送FIN包）取决 于是否还有数据需要发送给客户端，若有，则在发送FIN包之前均为此状态。因为不知道服务器还有没有数据要发送
- FIN_WAIT_2： 半关闭状态。 发送断开请求⼀⽅还有接收数据能⼒，但已经没有发送数据能⼒。

time_wait 是表示主动关闭连接的一方等待一段时间后，确认对方收到关闭连接请求并完成了关闭，而 close_wait 是表示等待本地应用程序关闭连接的状态。因此，当一个应用程序没有正确关闭连接时，就会出现大量的 close_wait 状态的 socket，导致系统资源的浪费和性能下降

#### 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

主要原因有两个方面：

- 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

#### 从浏览器中输入网址到显示页面的全过程？

```
 【浏览器地址栏输⼊URL回⻋后涉及到的流程】  

1.0 浏览器解析URL，将其分解成协议、主机名、端口号（如果有）、路径和查询字符串等各个部分。

1.1 查找DNS缓存 
    1. 先查找浏览器DNS缓存，看是否存放⽬标⽹络的IP地址;  
    2. 如果不在浏览器缓存，则浏览器将对操纵系统发起系统调⽤，查询操作系统本地缓存;  
    3. 如果不在操作系统本地缓存，则浏览器会查询与之相连的路由器缓存;  
    4.  如果不在路由器缓存，则浏览器会检查ISP【本地通信服务商】缓存; 
    5.  若以上四步均没有查询到⽬标⽹络的IP地址，则发起DNS查询。 

1.2 发起DNS查询 
	判断DNS服务器和我们的主机是否在同⼀⼦⽹内 
	1. 在同⼀⼦⽹，则采⽤ ARP 地址解析协议对 DNS 服务器进⾏ ARP 查询  
	2. 不在同⼀⼦⽹，则采⽤ ARP 地址解析协议对默认⽹关进⾏查询 
	若此时还是查询不到 IP 地址，则根据拿到 DNS 服务器或者默认⽹关的 IP 地址，继续进⾏ DNS 请求 
	使⽤53端⼝先向本地 DNS 服务器发送 UDP 请求包，此处⼀般使⽤ UDP 协议（如果响应包太⼤，则使⽤ TCP 协 议）  
	没有查询到 IP 地址： 则它会发送⼀个递归查询请求，⼀层⼀层向⾼层DNS服务器查询，直到查询到 IP 地址，则将结果返回 【解释：DNS 是分布式域名服务器，每台服务器只维护⼀部分 IP 地址到⽹络地址的映射，没有任何⼀台服务器能 够维持全部的映射关系】。  

1.3 封装TCP数据包 
	拿到 IP 地址后，根据 URL 中的端⼝可知端⼝号【HTTP：80；HTTPS：443】，⼀般先会先尝试建⽴ HTTP 连接;  准备 TCP 数据包：  
	步骤：  
	1. 将应⽤层传递下来的实际数据，在传输层添加TCP⾸部;  
	2. 将传输层传下来的数据在⽹络层添加IP⾸部;  
	3. 将⽹络层传输下来的数据，在数据链路层添加以太⽹⾸部，并在传输介质中进⾏传输。  
	
1.4 浏览器与⽬标服务器建⽴TCP连接 
	经过上述DNS和ARP查询流程后，浏览器会收到⽬标服务器的IP和MAC地址，然后经过三次握⼿后建⽴TCP连接; 
	1、使⽤HTTP协议  
	浏览器发送请求到服务器，如果使⽤的是HTTP协议，则服务器直接返回结果;  
	2、使⽤HTTPS协议  如果不是 HTTP 协议，则服务器会返回⼀个以 3 开头的᯿定向消息，告诉浏览器使⽤的 HTTPS，IP 没变，只是端⼝号变成 443；
	完成四次挥⼿；
	新建⽴ TCP 连接，将端⼝号修改为 443，同时沟通好双⽅的使⽤的认证算法、加密和解密算法，在次过程中也会 检查对⽅的 CA 安全证书，采⽤ SSL 加密技术进⾏传输数据。  

1.5 浏览器发送HTTP/HTTPS请求到web服务器 主要使⽤两种请求⽅式： 
	1. 浏览器发送get请求，要求⽬标服务器提供输⼊的⽹⻚;  
	2. 浏览器发送post请求，表示填写的是表单。  
	
1.6 服务器处理请求并发挥⼀个响应 
	服务器会从浏览器接受请求并将其传递给请求处理程序并响应;  
	
1.7 服务器发回⼀个HTTP响应
	⼀般响应包包含：请求的⽹⻚以及状态码，压缩类型，如何缓存的⻚⾯，设置的cookie;  
	
1.8 浏览器显示HTML⻚⾯ 
	1. 渲染HTML⻣架；涉及到Ajax技术;  
	2. 检查HTML标记并发送GET请求以获取⽹⻚上的其他元素【图像、CSS样式、JS⽂件等】，该静态⽂件⼀般由 浏览器缓存，再次访问，不⽤᯿新请求;  
	3. 最后会看到请求⾊彩斑斓的⽹⻚。 
```

#### cookie和session的区别

1. 存储位置不同

Cookie数据存储在客户端（即用户的浏览器）中，而Session数据存储在服务器端。具体来说，服务器会在内存或磁盘中创建一个Session对象，用于存储用户的会话信息。

1. 安全性不同

由于Cookie存储在客户端中，因此容易受到跨站点脚本攻击（XSS）和跨站点请求伪造攻击（CSRF）等安全威胁。为了保护Cookie的安全性，可以通过对Cookie设置HttpOnly、Secure等属性来防止这些攻击。而Session存储在服务器端，因此相对来说更加安全。

1. 数据量不同

Cookie可以存储的数据量有限，通常不超过4KB。而Session可以存储更大的数据量，因为它是存储在服务器端的。

1. 生命周期不同

Cookie有一个过期时间，在过期时间之前一直有效。而Session的生命周期取决于用户的活动情况，当用户关闭浏览器或长时间不活动时，Session会自动过期并被销毁。

1. 实现方式不同

Cookie是在服务器端通过**响应头中的Set-Cookie字段来设置的**，而客户端会将Cookie存储在浏览器中。而Session是通过在服务器端创建一个Session对象来实现的，客户端只是通过Session ID来标识不同的Session。

由于 Http 是一种无状态的协议，为了识别连接的发起者是谁，需要应用层自己去实现，因此诞生了 Session 和 cookie。Session 是保存在服务器端，Cookie 保存在客户端。

## 操作系统

#### B+和b树

CPU太快，磁盘太慢，所以要有个中间的东西，叫做页

datapage的整数倍

IO瓶颈问题

#### 线程池

我们预先创建好一系列线程，就好比后宫佳丽三千，然后皇上（线程池中枢）来了兴致（收到任务），就去翻一个妃子（线程池中某个线程）的牌子。妃子（线程）解决完需求后，回到后宫（线程池），等待下一次召唤。

不用创建和销毁，而是回收利用，所有池式结构都可以看做是一种对资源调度的缓冲，这就是线程池的精髓。

当前这个版本的线程池是基于互斥锁和条件变量实现的。

预告（画饼）：无锁线程池后续也会手撕。

线程池总体上可以分为三大组件。

- 任务队列（存还没有执行的任务）
- 执行队列（可以看成就是线程池，存放着可以用来执行任务的线程）
- 线程池管理中枢（负责封装前两个类，任务的分发，线程池的创建，销毁，等等。对外提供统一的接口

https://zhuanlan.zhihu.com/p/543476115

有两个队列，如果线程池满了，就放到任务队列里面去

线程池就是不需要代码自己创建线程，而是直接获取线程池中的线程，用完再还回去。相比手工创建和运行，能够降低线程创建和销毁的开销、提高响应速度、提高线程的可管理性。当你提交一个任务时，线程池首先会去看核心线程数是否达到上限，如果没有那就新建一个核心线程用来执行任务，否则去检查阻塞队列，如果阻塞队列未满，则加入阻塞队列，否则检查总线程数是否达到阈值，如果没有达到阈值，就建立一个非核心线程用来执行任务，否则执行线程池饱和策略。 核心线程数由 corePoolSize 参数决定，阻塞队列必须实现 BlockingQueue 接口，非核心线程达到存活的最长时间就销毁，饱和策略有：抛出异常（默认）、抛弃任务、抛弃最旧（下一个要运行）的任务、在主线程中执行任务。 不同线程池区别在于核心线程数是否固定、阻塞队列的实现（如ArrayBlockingQueue、LinkedBlockedQueue、PriorityBlockingQueue、DelayQueue、SynchronousQueue）、非核心线程数的最长存活时间等等参数的限定。



#### 条件变量

C++条件变量（Condition Variable）是一种多线程编程中的同步机制，用于线程之间的协调和通信。条件变量用于在某些条件满足时通知等待线程进行操作，以避免线程的无效轮询，从而提高程序的效率。

条件变量通常与互斥锁（Mutex）一起使用，以确保在访问共享资源时的互斥性。当一个线程在等待条件变量时，它会释放它持有的互斥锁，这样其他线程就可以访问共享资源。当满足条件时，通知线程会重新获得互斥锁，继续执行操作。

在C++11之前，条件变量需要与特定的线程库一起使用，例如Windows线程库的“Condition Variables”或Linux线程库的“POSIX Threads”。但是，C++11引入了标准库中的条件变量，使得跨平台的多线程编程更加方便。

在C++标准库中，条件变量通常由std::condition_variable类表示，它提供了wait()、notify_one()和notify_all()等方法，可以用于等待和唤醒线程。使用条件变量需要遵循一些约定和规则，例如等待前必须持有互斥锁等，以确保正确的线程同步。

#### 进程和线程的区别

进程是最基本的资源分配单位，线程是CPU最基本的执行单位。这指的是进程会分配heap，global variables等。而线程只会分配栈等资源

操作系统执行的基本单位是进程。进程是正在运行的程序的实例，包括程序代码、数据和进程控制块(PCB)。进程是操作系统资源分配的基本单位，它拥有独立的地址空间、堆栈、文件描述符和其他系统资源，同时也具有一定的独立性和并发性。操作系统通过进程的调度和管理来控制计算机资源的分配和使用，以满足不同进程的需求和优先级。

线程是否有自己的资源吗？ 有，会分配stack，stack pointer， program counter

两个进程是相互独立的，因为它们拥有各自独立的虚拟地址空间，互不干扰。每个进程拥有自己的代码段、数据段、堆栈等内存区域，可以独立地进行内存的读写操作，而且不会影响其他进程的内存。

此外，每个进程还拥有独立的文件描述符、进程ID、用户ID、组ID等资源，它们之间也是相互独立的。进程可以创建子进程，但是这些子进程也是相互独立的，除非它们之间进行了特殊的共享操作，如进程间通信（IPC）等。

虽然进程之间是相互独立的，但是它们可以通过进程间通信机制（如管道、消息队列、共享内存等）来实现数据的共享和协作，从而实现分布式计算、并发编程等功能。这些通信机制都是由操作系统提供的，它们允许不同进程之间进行数据交换和同步操作，从而提高系统的效率和可靠性。

1. 新建状态（New）：当线程对象被创建后，处于新建状态，此时尚未开始执行线程。
2. 就绪状态（Runnable）：当调用线程的 start() 方法后，线程会进入就绪状态，等待获取 CPU 时间片开始执行。就绪状态的线程可能会在等待锁、I/O 等操作时被阻塞。
3. 运行状态（Running）：线程获得了 CPU 时间片并开始执行，处于运行状态。此时线程可以访问 CPU 和内存等资源。
4. 阻塞状态（Blocked）：线程由于某些原因无法继续执行，进入阻塞状态，比如等待 I/O 完成或等待获取对象的锁等。阻塞状态的线程不会占用 CPU 时间片。
5. 等待状态（Waiting）：线程执行了某些操作后，需要等待其他线程或外部事件的通知才能继续执行，此时进入等待状态。如等待 join() 方法的返回或者调用了 wait() 方法等待其他线程的通知。
6. 计时等待状态（Timed Waiting）：和等待状态类似，不同的是等待一定时间后会自动返回，如 sleep() 方法等待指定时间后返回。
7. 终止状态（Terminated）：线程执行完任务后进入终止状态，线程执行完毕后自然结束，或者调用了 stop() 方法强制结束线程。

#### 进程之间通讯方式

**1**）数据传输：一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几兆字节之间。

2）共享数据：多个进程想要操作共享数据，一个进程对共享数据的修改，别的进程应该立刻看到。

3）通知事件：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。

4）资源共享：多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。

5）进程控制：有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。

**1) 管道PIPES，通常指⽆名管道。（固定的进程）**

 ① 半双⼯的，具有固定的读端和写端；

 ② 只能⽤于具有亲属关系的进程之间的通信；

 ③ 可以看成是⼀种特殊的⽂件，对于它的读写也可以使⽤普通的read、write函数。

但是它不是普通的⽂件，并不 属于其他任何⽂件系统，只能⽤于内存中。

```cpp
c++Copy code#include <unistd.h>
#include <stdio.h>

int main()
{
    int fd[2];
    pid_t pid;
    char buf[256];

    if (pipe(fd) < 0) {
        //  **④ Int pipe(int fd[2]);当⼀个管道建⽴时，会创建两个⽂件⽂件描述符，要关闭管道只需将这两个⽂件描述符关闭 即可。** 
        perror("pipe error");
        return -1;
    }

    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        close(fd[0]);
        write(fd[1], "Hello, parent process!", 23);
        exit(0);
    } else {
        close(fd[1]);
        read(fd[0], buf, 256);
        printf("Received message: %s\n", buf);
    }
// 数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关通常是指父子进程关系。
    return 0;
}
```

**2) FiFO（有名管道） 无关的进程也可以， 可以重用**

① FIFO可以再⽆关的进程之间交换数据，与⽆名管道不同；

 ② FIFO有路径名与之相关联，它以⼀种特殊设备⽂件形式存在于⽂件系统中；备注了pathname

管道内容是存放在内存上的，磁盘上的仅仅只是标识，FIFO是文件，存在磁盘上

```cpp
#include <unistd.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <stdio.h>
#include <string.h>

#define FIFO_NAME "/tmp/my_fifo"

int main()
{
    int fd;
    char buf[256];

    if (mkfifo(FIFO_NAME, 0666) < 0) {
        // Int mkfifo(const char* pathname,mode_t mode); 
        perror("mkfifo error");
        return -1;
    }

    pid_t pid;
    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        fd = open(FIFO_NAME, O_WRONLY);
        write(fd, "Hello, parent process!", 23);
        close(fd);
        _exit(0);
    } else {
        fd = open(FIFO_NAME, O_RDONLY);
        read(fd, buf, 256);
        printf("Received message: %s\n", buf);
        close(fd);
    }

    unlink(FIFO_NAME);

    return 0;
}

```



**3) 消息队列** 

① 消息队列，是消息的连接表，存放在内核中。⼀个消息队列由⼀个标识符来标识；

 ② 消息队列是⾯向记录的，其中的消息具有特定的格式以及特定的优先级； 

③ 消息队列独⽴于发送与接收进程。进程终⽌时，消息队列及其内容并不会被删除； 

④ 消息队列可以实现消息的随机查询 

消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，**接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。**可以把消息看做一个记录，具有特定的格式以及特定的**优先级**。

进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列。

消息队列与命名管道的比较：

相同之处：与命名管道一样，消息队列进行通信的进程可以是不相关的进程，同时它们都是通过发送和接收的方式来传递数据的。在命名管道中，发送数据用write，接收数据用read，则在消息队列中，发送数据用msgsnd，接收数据用msgrcv。而且它们对每个数据都有一个最大长度的限制。

消息队列的优势在于：
1、消息队列也可以独立于发送和接收进程而存在，从而消除了在同步命名管道的打开和关闭时可能产生的困难。
2、同时通过发送消息还可以避免命名管道的同步和阻塞问题，不需要由进程自己来提供同步方法。
3、接收程序可以通过消息类型有选择地接收数据，而不是像命名管道中那样，只能默认地接收。

**4) 信号量**

① 信号量

是⼀个计数器，信号ᰁ⽤于实现进程间的互斥与同步，⽽不是⽤于存储进程间通信数据； 

② 信号ᰁ⽤于进程间同步，若要在进程间传递数据需要结合共享内存； ③ 信号ᰁ基于操作系统的PV操作，程序对信号ᰁ的操作都是原⼦操作；

1. 用于通知接收进程某个事件已经发生。

**5) 共享内存 （mmap）**

① 共享内存，指两个或多个进程共享⼀个给定的存储区；

 ② 共享内存是最快的⼀种进程通信⽅式，因为进程是直接对内存进⾏存取； 

③ 因为多个进程可以同时操作，所以需要进⾏同步； 

④ 信号量+共享内存通常结合在⼀起使⽤。

好处

```
省去了繁琐的I/O操作：使用mmap可以将文件或设备直接映射到内存中，进程可以直接访问内存中的数据，而不需要调用I/O操作（例如read()和write()等），避免了繁琐的数据拷贝和上下文切换操作。

避免了频繁的系统调用：使用mmap可以避免频繁的系统调用，减少了内核和用户态之间的上下文切换次数，提高了程序的性能和响应速度。

提高了文件访问效率：使用mmap可以利用操作系统的文件缓存机制，减少了文件的I/O次数，提高了文件的访问效率。

简化了代码实现：使用mmap可以简化代码实现，减少了对文件读写的操作，提高了程序的可读性和可维护性。

方便共享内存：使用mmap可以将同一个文件映射到不同的进程地址空间中，从而方便进程之间的数据共享。
```



坏处

```
内存管理的复杂性：使用mmap将文件映射到内存中后，需要对内存进行管理，包括申请和释放内存等操作，这需要更加复杂的内存管理机制，容易出现内存泄漏、内存冲突等问题。

对内存资源的消耗：使用mmap将文件映射到内存中后，会占用一部分内存资源，当需要处理大量的文件时，可能会导致内存资源不足，影响系统的稳定性。

可能会影响文件的一致性：如果多个进程同时对同一个文件进行mmap映射，由于内存映射是共享的，可能会导致文件的一致性问题，例如多个进程同时修改文件时，可能会导致文件内容不一致或者损坏。

可能会受到操作系统限制：操作系统可能会对mmap映射的大小、数量、映射文件的类型等进行限制，从而可能会限制程序的性能或者功能。
```



1. 管道

```cpp
c++Copy code#include <unistd.h>
#include <stdio.h>

int main()
{
    int fd[2];
    pid_t pid;
    char buf[256];

    if (pipe(fd) < 0) {
        perror("pipe error");
        return -1;
    }

    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        close(fd[0]);
        write(fd[1], "Hello, parent process!", 23);
        exit(0);
    } else {
        close(fd[1]);
        read(fd[0], buf, 256);
        printf("Received message: %s\n", buf);
    }

    return 0;
}
```

1. 共享内存

```cpp
#include <unistd.h>
#include <sys/mman.h>
#include <fcntl.h>
#include <stdio.h>
#include <string.h>

#define SHM_NAME "/my_shared_memory"
#define SHM_SIZE 4096

int main()
{
    int shm_fd;
    char *shm_ptr;

    shm_fd = shm_open(SHM_NAME, O_CREAT | O_RDWR, 0666);
    ftruncate(shm_fd, SHM_SIZE);
    shm_ptr = (char *) mmap(NULL, SHM_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, 0);

    pid_t pid;
    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        memcpy(shm_ptr, "Hello, parent process!", 23);
        exit(0);
    } else {
        sleep(1);
        printf("Received message: %s\n", shm_ptr);
    }

    munmap(shm_ptr, SHM_SIZE);
    close(shm_fd);
    shm_unlink(SHM_NAME);

    return 0;
}
```

1. 信号量

```cpp
#include <unistd.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/sem.h>
#include <stdio.h>
#include <stdlib.h>

#define KEY 1234

union semun {
    int val;
    struct semid_ds *buf;
    unsigned short *array;
    struct seminfo *__buf;
};

int main()
{
    int sem_id, pid;
    union semun sem_union;

    sem_id = semget(KEY, 1, 0666 | IPC_CREAT);
    sem_union.val = 1;
    semctl(sem_id, 0, SETVAL, sem_union);

    if ((pid = fork()) < 0) {
        perror("fork error");
        return -1;
    } else if (pid == 0) {
        struct sembuf sem_op = {0, -1, 0};
        semop(sem_id, &sem_op, 1);
        printf("Child process acquire semaphore.\n");
        sleep(1);
        sem_op.sem_op = 1;
        semop(sem_id, &sem_op, 1);
        printf("Child process release semaphore.\n");
        exit(0);
    } else {
        sleep(2);
        printf("Parent process acquire semaphore.\n");
        struct sembuf sem_op = {0, -1, 0};
        semop(sem_id, &sem_op, 1);
        printf("Parent process release semaphore.\n");
    }

    semctl(sem_id, 0, IPC
```



**6） socket编程**

两个进程可以通过操作系统提供的进程间通信（IPC）机制来共享资源。

首先是共享内存，它允许多个进程共享同一块物理内存区域，从而可以直接读写对方进程的内存，达到数据共享的目的。操作系统会将这个物理内存区域映射到各个进程的虚拟地址空间，使得每个进程都可以访问到这个区域。

其次是管道，它允许一个进程向另一个进程发送数据，也可以接收另一个进程发送过来的数据。管道通常是单向的，而且只能在具有亲缘关系的进程之间使用。

还有消息队列，它可以在进程之间传递消息，从而实现进程之间的通信和同步。消息队列是一个存放消息的缓冲区，它允许一个进程往队列中写入消息，另一个进程从队列中读取消息。

最后是套接字，它是一种通用的进程间通信机制，可以在不同计算机之间进行通信。套接字通常用于网络编程，它允许一个进程向另一个进程发送数据，并且可以进行网络传输。

除了这些通信机制外，进程之间还可以通过文件共享、信号等方式进行通信。需要注意的是，进程之间共享资源可能会存在竞争和同步问题，需要使用锁、信号量、互斥量等同步机制来避免资源的冲突和错误。

#### 线程之间的通信方式

1. 共享变量：线程之间可以通过共享变量来进行通信。通过在多个线程之间共享同一块内存区域来实现，线程可以读取和修改共享变量的值，从而实现信息的传递和同步。
2. 信号量：信号量是一种计数器，用于控制多个线程对共享资源的访问。当一个线程需要访问共享资源时，它会首先尝试获取信号量，如果信号量的值大于0，则表示有可用的资源，线程可以访问共享资源并将信号量的值减1；如果信号量的值等于0，则表示没有可用的资源，线程需要等待其他线程释放资源后才能继续访问。
3. 互斥锁：互斥锁是一种同步机制，用于保护共享资源不被多个线程同时访问。当一个线程需要访问共享资源时，它会先获取互斥锁，如果互斥锁没有被其他线程占用，则表示可以访问共享资源，线程执行相应的操作并释放互斥锁；如果互斥锁已经被其他线程占用，则表示需要等待其他线程释放互斥锁后才能继续访问。
4. 条件变量：条件变量用于在线程间传递信号，它允许一个线程在满足某个特定条件之前等待其他线程发出信号。当一个线程需要等待某个条件成立时，它会先释放互斥锁并等待条件变量的信号，其他线程在满足条件时会发出信号并唤醒等待的线程，等待的线程被唤醒后会重新获取互斥锁并继续执行。



读写锁的底层实现

```
读写锁的底层实现通常是使用互斥锁和条件变量结合实现的。读写锁可以分为读锁和写锁，多个线程可以同时获取读锁，但只有一个线程可以获取写锁。当有线程获取写锁时，其他线程无法获取读锁和写锁，直到写锁被释放。

具体来说，读写锁的底层实现可以分为两种方式：

读写锁的互斥锁实现
使用一个互斥锁来保护读写锁的内部数据结构，比如读写计数器和等待队列等。读锁和写锁的获取和释放操作都需要先获取这个互斥锁，保证同一时刻只有一个线程在修改读写锁的内部状态。

当有线程需要获取读锁时，会判断是否有其他线程持有写锁，如果有则需要等待写锁释放，否则可以获取读锁。当有线程需要获取写锁时，会判断是否有其他线程持有读锁或者写锁，如果有则需要等待读锁和写锁全部释放，否则可以获取写锁。在获取和释放读锁和写锁时，需要修改读写计数器的值，以便正确地判断是否有其他线程持有读锁或者写锁。

读写锁的条件变量实现
使用两个条件变量来分别控制读锁和写锁的获取和释放。读写锁的内部数据结构可以只使用原子变量来保存读写计数器和等待队列等，避免使用互斥锁。

当有线程需要获取读锁时，会判断是否有其他线程持有写锁，如果有则需要等待写锁释放，否则可以获取读锁并增加读计数器。当有线程需要获取写锁时，会判断是否有其他线程持有读锁或者写锁，如果有则需要等待读锁和写锁全部释放，否则可以获取写锁并将写标志置为true。在释放读锁和写锁时，需要修改读写计数器的值，并且需要通知等待在条件变量上的其他线程。如果当前线程持有写锁，则需要通知等待写锁的线程；否则，如果读计数器为0，则需要通知等待写锁的线程，否则需要通知等待读锁的线程。

总之，读写锁的底层实现主要是通过互斥锁或条件变量等基本的同步原语来保证多个线程之间的访问正确性和一致性。不同的实现方式各有优缺点，应根据具体的场景来选择适当的实现方式。
```



#### 锁的类型

```
互斥锁（Mutex Lock）：也叫互斥量，是一种基本的锁机制。只有拥有互斥锁的线程才能访问被保护的资源，其他线程必须等待互斥锁被释放才能访问。常用的互斥锁包括pthread_mutex_t（POSIX标准的互斥锁）、std::mutex（C++11标准库中的互斥锁）等。

读写锁（Read-Write Lock）：读写锁可以分为读锁和写锁，多个线程可以同时获取读锁，但只有一个线程可以获取写锁。当有线程获取写锁时，其他线程无法获取读锁和写锁，直到写锁被释放。读写锁可以提高多线程读操作的并发性能，适用于读操作频繁，写操作较少的场景。常用的读写锁包括pthread_rwlock_t（POSIX标准的读写锁）、std::shared_mutex（C++17标准库中的读写锁）等。
在C++中，读写锁的使用方式和互斥锁类似，可以使用std::shared_mutex来定义一个读写锁对象。和互斥锁不同的是，读写锁提供了两种操作：读操作：通过std::shared_lockstd::shared_mutex获取读锁，多个读操作可以同时持有读锁。写操作：通过std::unique_lockstd::shared_mutex获取写锁，只有一个写操作可以持有写锁，其他读写操作都需要等待写锁释放。读写锁的具体实现方式可以基于互斥锁和条件变量实现，也可以基于原子操作实现。不同的实现方式在性能和可靠性上可能存在差异，需要根据具体的应用场景选择合适的实现方式。

条件变量（Condition Variable）：条件变量用于线程之间的通信，可以等待某个条件满足后再继续执行。条件变量需要和互斥锁一起使用，等待条件时会释放互斥锁，等待结束后再重新获取互斥锁。常用的条件变量包括pthread_cond_t（POSIX标准的条件变量）、std::condition_variable（C++11标准库中的条件变量）等。

自旋锁（Spin Lock）：自旋锁是一种忙等待的锁机制，线程会一直循环检查锁是否可用，直到获取到锁为止。自旋锁适用于保护临界区很小、加锁时间很短的情况。常用的自旋锁包括pthread_spinlock_t（POSIX标准的自旋锁）、std::atomic_flag（C++11标准库中的原子标志）等。

递归锁（Recursive Lock）：递归锁允许同一线程多次获取锁，每次获取锁后需要相应的释放锁，否则会导致死锁。递归锁适用于需要递归调用加锁函数的场景。常用的递归锁包括pthread_mutex_t（POSIX标准的递归锁）、std::recursive_mutex（C++11标准库中的递归锁）等。
```



#### 上下文开销问题

上下文开销是指当一个进程或线程从一个上下文切换到另一个上下文时，由于需要保存和恢复上下文信息所带来的开销。这些上下文信息包括程序计数器、寄存器、堆栈指针、状态字等。上下文切换是操作系统进行多任务调度的必要操作，但是频繁的上下文切换会带来较大的性能开销。

上下文切换的原因有多种，例如：

1. 抢占式调度：当一个进程或线程的时间片用完时，操作系统会抢占其CPU资源，并将其上下文信息保存下来，然后调度下一个进程或线程运行。
2. 阻塞式调度：当一个进程或线程需要等待某些事件发生时，如IO操作完成，操作系统会将其挂起，并将其上下文信息保存下来，等待事件发生后再恢复运行。
3. 中断处理：当硬件设备发生中断时，操作系统需要暂停当前进程或线程的执行，转而处理中断请求，这也需要进行上下文切换。

由于上下文开销的存在，操作系统在设计和实现调度算法时需要权衡进程/线程的切换频率和开销，以提高系统的性能和响应速度。通常的优化方法包括：

1. 尽量减少上下文切换的发生，如使用合适的调度算法、避免死锁和饥饿等问题。
2. 减少上下文信息的保存和恢复开销，如使用硬件支持的快速上下文切换技术、优化**内核态和用户态**之间的切换等。
3. 提高CPU的运行速度，以缩短上下文切换所带来的时间开销。

### 对进程进行管理

操作系统如何对进程进行管理（回答了一下进程调度的算法，不知道对不对）

进程的状态

初始化列表

#### 内存分页置换算法

1. 最优算法（Optimal Algorithm）：该算法会根据页面在未来的使用情况来决定置换哪些页面。具体来说，它会选择最长时间内不再被使用的页面进行置换。但是，由于无法预知未来页面的访问情况，因此最优算法的实际应用较少。
2. 先进先出算法（First In First Out, FIFO）：该算法会将最先进入内存的页面置换出去。该算法实现简单，但是由于没有考虑页面的使用情况，因此可能会导致一些常用的页面被频繁地置换出去，从而影响系统的性能。
3. 最近最少使用算法（Least Recently Used, LRU）：该算法会根据页面最近一次被使用的时间来决定置换哪些页面。具体来说，它会将最长时间内未被访问的页面进行置换。该算法相对于FIFO算法来说，能够更好地利用内存空间，但是实现起来比较复杂。
4. 时钟算法（Clock）：该算法会维护一个指针，指向当前要被检查的页面。当页面被访问时，会将页面的访问位设置为1。当需要置换页面时，时钟算法会从指针所指位置开始查找页面的访问位。如果访问位为0，则说明该页面未被使用，可以进行置换；否则将访问位设为0，继续查找下一个页面。该算法实现简单，但是可能会出现页面访问位频繁变化的情况，从而导致算法效率下降。



#### 同步机制

1. 自旋锁：当线程需要访问共享资源时，它会反复检查锁是否可用，直到获得锁为止，这个过程称为自旋。自旋锁适用于共享资源的锁定时间很短的情况，因为自旋锁会一直占用 CPU 时间。
2. 读写锁：读写锁允许多个线程同时读共享资源，但只允许一个线程写共享资源。这种锁适用于读操作比写操作更频繁的场景。
3. 条件变量：条件变量是一种用于线程间通信的机制，它可以让一个线程等待另一个线程的信号，当条件满足时，另一个线程会发送信号通知等待线程继续执行。条件变量通常和互斥锁一起使用，用于实现更复杂的同步操作。
4. 信号量：信号量是一种用于控制资源访问的计数器，它可以用来实现多个线程之间的同步和互斥。

除了这些同步机制外，还可以使用无锁算法和锁粒度更细的数据结构来避免锁带来的性能问题。但是需要注意的是，不同的同步机制和算法适用于不同的场景，需要根据具体的应用场景选择最合适的同步机制。

#### 抢占式和非抢占式

抢占式和非抢占式是操作系统中用于调度进程或线程的两种不同方式。

非抢占式调度是指进程或线程持有 CPU 的时间是不受外部干预的，只有在它自己执行完任务之后，才会主动释放 CPU 的控制权，让其他进程或线程获得 CPU 时间。在非抢占式调度中，进程或线程的运行时间是可预测的，但如果某个进程或线程出现了长时间的阻塞或死循环，会导致系统无法及时响应其他请求。

抢占式调度是指操作系统可以在任何时候中断当前进程或线程的执行，将 CPU 的控制权交给其他进程或线程，从而实现对进程或线程的强制抢占。在抢占式调度中，进程或线程的运行时间是不可预测的，但可以更好地保证系统的响应速度和并发性能。

一般来说，抢占式调度比非抢占式调度更加灵活和高效，因为它可以更好地处理系统资源的竞争和分配问题。但是，抢占式调度需要更多的系统开销和处理器时间，可能会影响系统的稳定性和响应速度。因此，在设计操作系统时，需要根据具体的应用场景和性能要求，选择合适的调度方式。



在执行过程的中间，执行被中断，而; 在非抢占式调度中，在执行过程中不会中断执行

抢先式调度会遭受从就绪状态到运行状态(反之亦然)之间进行切换以及维护就绪队列的开销。 另一方面，非抢占式调度不会遭受将进程从运行状态切换到就绪状态的开销。

当高优先级的进程频繁到达就绪队列时，低优先级的进程必须等待很长时间，并且可能会在抢占式调度中饿死。 而在非抢占式调度中，如果将CPU分配给具有较大突发时间的进程，则突发时间最小的进程可能不得不挨饿。

抢先式调度必须维护共享数据的完整性，因此这与成本相关，但非抢先式调度则不是这种情况。

这两个调度之间的主要区别在于，在非抢占式调度中，CPU被分配给进程，直到它完成执行或从运行状态切换到等待状态。 而在抢占式调度中，CPU将在有限的时间内分配给某个进程。

#### 操作系统的内存管理机制

不同进程之间的地址隔离是通过操作系统实现的。每个进程都有其独立的虚拟地址空间，其访问的内存地址不会直接映射到物理内存上，而是通过内存管理单元（MMU）进行地址转换。MMU负责将虚拟地址转换为物理地址，同时也负责检查进程对内存的访问权限。

操作系统通过使用分页和分段机制实现虚拟地址到物理地址的转换。在分页机制下，虚拟地址被划分为大小相等的页，每个页映射到物理内存中的一页。在分段机制下，虚拟地址被划分为不同的段，每个段映射到物理内存中的一块连续的地址空间。

操作系统还通过给每个进程分配独立的页表或段表来保证不同进程之间的地址隔离。每个进程的页表或段表中只包含该进程所拥有的内存地址的映射关系，从而防止进程之间相互访问彼此的内存。

此外，操作系统还可以使用内存保护机制来限制进程对内存的访问权限。例如，操作系统可以将某些内存区域标记为只读或禁止访问，从而保护系统的安全性和稳定性。

#### Notify和notifyAll的区别

前者随机唤醒一个该锁的线程，后者是全部唤醒

#### 并发编程

并发（Concurrency）是指同时执行多个任务的能力，通常通过多线程、多进程等技术来实现。在并发程序中，多个线程或进程可以同时运行，彼此之间互相协调、共享资源、完成任务。

以下是一些关于并发实现和流程的简单问题：

1. 什么是锁？

锁是一种并发控制机制，用于控制对共享资源的访问。在多线程或多进程环境中，如果多个线程或进程同时访问共享资源，可能会导致数据竞争和不一致的结果。锁通过互斥的方式，确保在同一时刻只有一个线程或进程能够访问共享资源，从而避免竞争和冲突。

1. 什么是线程池？

线程池是一种并发执行任务的机制，它维护了一定数量的线程，在需要执行任务时从池中分配线程，执行完任务后将线程返回到池中。线程池可以减少线程的创建和销毁，避免因线程频繁创建和销毁而导致的性能问题。

1. 什么是死锁？

死锁是指在并发程序中，两个或多个线程或进程因互相等待对方释放资源而陷入无限等待的状态。死锁是一种常见的并发问题，通常可以通过合理的资源分配和使用锁的策略来避免。

1. 并发程序的调试有什么难点？

并发程序的调试比较困难，因为多个线程或进程可以同时运行，彼此之间的执行顺序和交互不易预测。常见的并发调试问题包括数据竞争、死锁、活锁、饥饿等。为了解决这些问题，可以使用调试工具、日志记录、调试信息输出等技术，对并发程序进行逐步调试和排查问题。

## 数据结构

- 说一下二叉树和平衡二叉树（平衡二叉树有些不记得了）

#### 链表的实现

1. 链表中的元素由节点（Node）组成，每个节点包含两部分数据：数据域（Data）和指针域（Pointer）。
2. 数据域存储节点的数据，指针域存储下一个节点的地址，通过指针域将各个节点串联起来形成链表。
3. 链表中的元素可以动态添加或删除，不需要预先指定大小。
4. 链表不支持随机访问，只能从头节点开始依次遍历整个链表来查找或操作指定节点。
5. 链表可以实现高效的插入和删除操作，时间复杂度为O(1)。

#### Hash的实现方式

哈希是一种常见的数据结构，用于将任意大小的数据映射到固定大小的值。哈希的实现方式可以分为以下两种：

1. 散列函数（Hash Function）

哈希表的核心是散列函数，它将任意大小的输入数据映射到固定大小的哈希值。散列函数需要满足以下要求：

- 相同的输入数据必须映射到相同的哈希值。
- 不同的输入数据尽可能映射到不同的哈希值，以减少哈希冲突的概率。

常见的散列函数有MD5、SHA-1、SHA-256等。

1. 哈希表（Hash Table）

哈希表是一种数据结构，它通过散列函数将任意大小的输入数据映射到一个固定大小的哈希值，并将这个哈希值作为数组的下标来存储数据。哈希表的实现包括以下几个步骤：

- 创建一个固定大小的数组，数组的每个元素都是一个链表。
- 输入数据经过散列函数映射到一个哈希值。
- 将输入数据存储到数组中对应的链表中。

当查询数据时，先将输入数据经过散列函数映射到一个哈希值，然后在数组中对应的链表中查找是否存在该数据。

哈希表的优点是可以快速地插入和查找数据，时间复杂度为O(1)。然而，哈希表的缺点是可能存在哈希冲突，即不同的输入数据映射到相同的哈希值，这时需要通过链表等方式来解决哈希冲突，这会影响哈希表的性能。因此，在设计哈希表时，需要合理选择散列函数和数组大小，以减少哈希冲突的概率，从而提高哈希表的性能。



#### DFS和BFS的区别

1. 遍历的方式

DFS（Depth First Search）是一种深度优先遍历算法，它从起点开始，选择一个未访问过的相邻节点，沿着这个节点继续往下访问，直到到达最深的节点或所有的节点都被访问过。如果当前节点已经没有未访问的相邻节点，则回溯到上一个节点，继续遍历其他未访问的节点。DFS使用栈或递归实现。

BFS（Breadth First Search）是一种广度优先遍历算法，它从起点开始，依次遍历所有与该节点相邻的节点，然后依次遍历与这些节点相邻的所有未访问过的节点，直到所有节点都被访问过为止。BFS使用队列实现。

1. 遍历的顺序

DFS是先深度遍历，直到到达最深的节点，然后回溯到上一个节点继续遍历。因此，DFS遍历的顺序是先深度后广度。

BFS是先广度遍历，依次访问与当前节点相邻的所有节点，然后再依次访问与这些节点相邻的所有节点。因此，BFS遍历的顺序是先广度后深度。

总的来说，DFS和BFS都是常见的图遍历算法，它们的主要区别在于遍历的方式和遍历的顺序。DFS是一种深度优先遍历算法，遍历顺序是先深度后广度；BFS是一种广度优先遍历算法，遍历顺序是先广度后深度。选择哪种遍历算法取决于具体的应用场景。

#### 红黑树和B+树的区别

1. 数据存储方式：红黑树是一种二叉搜索树，每个节点保存一个key和对应的value；而B+树是一种多叉树，只有叶子节点保存key和value，非叶子节点只保存key。
2. 节点结构：红黑树的节点包含key、value、左右子节点和一个颜色属性；B+树的节点包含key和指向子节点的指针，而叶子节点还包含value。
3. 平衡性维护：红黑树通过节点颜色的变化来维护平衡性，通过旋转操作来保持树的平衡；而B+树通过调整节点的大小来维护平衡性，通过分裂、合并、插入等操作来保持树的平衡。
4. 磁盘访问：B+树通常用于磁盘存储，因为它的节点可以存储多个key和value，并且叶子节点形成了一个有序链表，可以支持范围查询和顺序访问，这对于磁盘访问非常有利；而红黑树通常用于内存存储，因为它的节点不需要存储指针，可以更好地利用内存。
5. 查找效率：在查找单个key的情况下，红黑树的查找效率略高于B+树，因为它的节点包含value，可以直接返回结果，而B+树需要沿着指针查找到叶子节点才能返回结果。但是在范围查询和顺序访问的情况下，B+树的效率更高，因为它的叶子节点形成了有序链表，可以直接按照顺序访问。



红黑树、B树、B+树都是常用的自平衡树，用于实现关键字的快速查找和排序。它们之间的主要区别在于其平衡性、节点的度以及数据的存储方式。

1. 平衡性

红黑树是一种近似平衡的二叉搜索树，它的左右子树的高度差不超过2倍。而B树和B+树是多路搜索树，可以是2-3树、2-3-4树、B树等等，其节点的度可以大于2。

1. 节点的度

B树和B+树的节点度是大于2的，而红黑树的节点度为2。

1. 数据存储方式

在B树中，每个节点存储的都是关键字和数据，而在B+树中，非叶子节点只存储关键字，而数据都存储在叶子节点中。这样做的好处是可以减少非叶子节点的大小，从而使得树的高度更矮，查询速度更快。而红黑树则是将数据存储在每个节点中。

1. 应用场景

红黑树一般用于实现高效的数据结构，比如C++中的STL库中的map、set等。B树和B+树则主要用于实现高效的文件系统和数据库系统，因为它们能够在磁盘上高效地存储和管理大量数据。

总的来说，红黑树和B、B+树都是常用的自平衡树，用于实现高效的数据结构和文件系统或数据库系统。它们之间的区别在于平衡性、节点的度以及数据的存储方式。

#### 每个树的应用场景

AVL树

```cpp
以下是一些 AVL 树的应用场景：

数据库索引：数据库中的许多查询操作需要在一个大数据集合中进行查找，因此需要高效的数据结构来存储和维护这些数据集合。AVL树可以用作数据库索引结构，支持快速的数据查找、插入、删除等操作。

编辑器的撤销和重做操作：许多文本编辑器支持撤销和重做操作，这需要维护一个有序的操作序列，以便在用户撤销操作时回退到上一个状态。AVL树可以用作这种操作序列的数据结构，支持快速的插入、删除和查询操作。

路由表：在计算机网络中，路由表用于确定数据包的下一个跳，以便正确地将数据包发送到目标主机。AVL树可以用作路由表的数据结构，支持快速的查找操作。

字典：字典是一种键值对的数据结构，其中每个键都与一个值相关联。AVL树可以用作字典的实现，支持快速的查找、插入、删除等操作。
```

红黑树,B和B+树

```
红黑树一般用于实现高效的数据结构，比如C++中的STL库中的map、set等。B树和B+树则主要用于实现高效的文件系统和数据库系统，因为它们能够在磁盘上高效地存储和管理大量数据。

总的来说，红黑树和B、B+树都是常用的自平衡树，用于实现高效的数据结构和文件系统或数据库系统。它们之间的区别在于平衡性、节点的度以及数据的存储方式。
```

***1、B+Tree vs B Tree***

B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。

另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。

***2、B+Tree vs 二叉树***

对于有 N 个叶子节点的 B+Tree，其搜索复杂度为`O(logdN)`，其中 d 表示节点允许的最大子节点个数为 d 个。

在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。

而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 `O(logN)`，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。

***3、B+Tree vs Hash***

Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。

但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。

### [#](https://xiaolincoding.com/mysql/index/index_interview.html#按物理存储分类)按物理存储分类



## Linux命令

1. 监控角度不同：`free -h` 命令主要关注系统内存使用情况，包括总内存大小、已使用内存大小、可用内存大小、缓存内存大小等，而 `top` 命令则可以监控系统的进程、CPU、内存、IO 等各方面指标。

netstat -napt 查看tcp连接

free

grep

ps ajx | more

`more`: 分页查看命令输出结果。

#### ps

`ps`: 显示当前进程的状态。

- `-j`: 该选项会显示进程的作业控制信息，包括进程所属用户、进程ID、父进程ID、进程状态、CPU和内存使用情况等信息，以及进程所在的进程组ID、会话ID和作业ID等信息。这个选项主要用于查看进程的作业控制信息，适用于 Linux 和 BSD 系统。
- `-u`: 该选项会显示进程的用户信息，包括进程所属用户、进程ID、CPU和内存使用情况、启动时间等信息。这个选项主要用于查看进程的用户信息，适用于大多数 Unix 系统，如 Linux、MacOS、FreeBSD 等。

-u 可以单独筛选某个用户

- `-aux`: 选项，其中 a 表示显示所有进程，包括其他用户的进程；u 表示显示进程的详细信息，包括进程所属用户、进程启动时间、进程使用的CPU和内存等信息；x 表示显示没有控制终端的进程。
- `|`: 管道符号，将前面的命令的输出作为后面命令的输入。
- `grep`: 在输出中查找包含指定字符或字符串的行。
- 参数：指定需要查找的进程的名称或关键字。

在 Linux 操作系统，我们可以使用 `route -n` 命令查看当前系统的路由表。

在 Linux 系统中，我们可以使用 `arp -a` 命令来查看 ARP 缓存的内容。

- 文件描述符限制

  ，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：

  - **系统级**：当前系统可打开的最大数量，通过 `cat /proc/sys/fs/file-max` 查看；
  - **用户级**：指定用户可打开的最大数量，通过 `cat /etc/security/limits.conf` 查看；
  - **进程级**：单个进程可打开的最大数量，通过 `cat /proc/sys/fs/nr_open` 查看；



#### 改变用户的权限

##### 只读权限

如果想要将 Linux 文件设置为所有用户只读属性，可以使用 444 权限。这将允许所有用户读取该文件，但不允许修改或执行该文件。

要将文件设置为 444 权限，可以使用以下命令：

```bash
chmod 444 filename
```

其中，filename 是要修改权限的文件名。

相反，如果想要允许其他用户对文件进行修改和执行操作，可以使用 666 权限。这将允许所有用户读取、写入和执行该文件。

要将文件设置为 666 权限，可以使用以下命令：

```bash
chmod 666 filename
```

要将 Linux 文件设置为所有用户只读属性，可以使用 chmod 命令。

1. 首先，打开终端并进入要修改权限的文件所在的目录。
2. 然后，使用以下命令将该文件设置为所有用户只读属性：

```bash
chmod a-wx,u+r filename
```

其中，a-wx 表示删除所有用户的写入和执行权限，u+r 表示为文件所有者添加读取权限。filename 是要修改权限的文件名。

1. 如果要修改整个目录下的所有文件为只读属性，可以使用以下命令：

```bash
chmod -R a-wx,u+r directoryname
```

其中，-R 表示递归地修改目录下的所有文件和子目录，directoryname 是要修改权限的目录名。

这样设置后，所有用户都将只能读取该文件或目录，不能修改或删除它们。需要注意的是，如果要对某个文件或目录进行修改或删除操作，需要将其权限重新设置为可写或可执行属性。

- a=r：表示将文件的所有用户的权限设置为只读，即仅允许读取文件内容，不允许写入或执行该文件。这是一种绝对权限的设置方式，文件的权限将仅限于读取。
- a+r：表示为文件的所有用户添加读取权限，即允许所有用户读取该文件的内容。该命令不会影响原来的写入和执行权限设置，如果原先没有写入和执行权限，添加读取权限也不会影响文件的权限。

drwx|rwx|rwx

第一个file or directory

第二个 owner permission

第三个 group permission

第三个 global permission（for everybody else(other) )

`chmod ugo+r af_file`

u user

g group

o other

##### kill函数

在Linux或Unix系统中，kill命令可以用来终止（或杀死）一个进程。kill命令可以使用不同的参数来指定终止的方式。以下是一些常用的参数：

- `kill PID`：终止指定PID的进程。
- `kill -s SIGNAL PID`：向指定PID的进程发送指定信号，可以使用信号名称或信号编号。例如，`kill -s TERM 1234`会向PID为1234的进程发送SIGTERM信号，以请求进程正常退出。
- `kill -l`：列出所有可用的信号名称和编号。
- `killall NAME`：终止所有名为NAME的进程。
- `killall -s SIGNAL NAME`：向所有名为NAME的进程发送指定信号，可以使用信号名称或信号编号。例如，`killall -s HUP apache2`会向所有名为apache2的进程发送SIGHUP信号，以重新读取配置文件。

请注意，kill命令需要足够的权限才能终止其他用户的进程。

- `kill -9` 掉了子进程能被回收掉吗

当父进程被强制杀死时（例如使用kill -9命令），子进程通常会成为孤儿进程（orphan process），即没有父进程的进程。在这种情况下，孤儿进程的父进程ID被设置为1，也就是init进程，init进程会自动接管孤儿进程，并成为它们的父进程。

因此，当你强制杀死父进程时，子进程会被init进程接管，init进程会负责回收孤儿进程的资源。但是，如果子进程已经变成了僵尸进程（zombie process），则需要使用wait()或waitpid()等系统调用来回收子进程的资源。

需要注意的是，尽管孤儿进程会被init进程接管，但是这种情况下会产生大量的孤儿进程，可能会影响系统的稳定性和性能。因此，在编写应用程序时，需要正确处理子进程的退出和资源回收，避免产生孤儿进程。

孤儿进程是指其父进程已经终止或异常结束，而该进程仍然在运行的进程。这种进程没有父进程可以处理它的退出状态和释放其资源，因此它们通常被操作系统接管，即由 init 进程接管，成为孤儿进程。孤儿进程状态下，它们的父进程ID被设置为1。操作系统会自动将孤儿进程的父进程ID设置为1，由 init 进程来负责处理其退出状态和释放资源。

而僵尸进程是指进程已经执行完毕，但是其父进程没有及时调用wait()或waitpid()等系统调用来获取子进程的退出状态信息。在这种情况下，子进程的退出状态信息会被操作系统保留，成为僵尸进程。僵尸进程会占用系统资源，导致系统的稳定性和性能下降。因此，需要及时调用wait()或waitpid()等系统调用来回收僵尸进程的资源。

简单来说，孤儿进程是指父进程结束了，而子进程还在运行；而僵尸进程是指子进程已经结束了，但是父进程还没有处理它的退出状态。两者的处理方式也不同，孤儿进程由 init 进程接管，而僵尸进程需要通过wait()等系统调用来回收资源。

bt 10

#### gdb调试

1. 调试崩溃程序：当程序崩溃时，使用 gdb 可以查看程序崩溃时的堆栈跟踪，以及变量的当前值等信息。这些信息通常可以帮助确定程序中的错误。
2. 调试非图形界面应用程序：对于没有 GUI 界面的应用程序，使用 gdb 可以轻松地设置断点，查看变量的值，单步执行程序等。
3. 调试多线程程序：gdb 可以轻松地调试多线程程序，查看不同线程的状态和变量的值等。

##### gdb多线程调试

在 gdb 中，调试多线程程序通常需要使用以下命令：

1. `set follow-fork-mode`：设置子进程如何被跟踪。有三个选项：`parent`，表示跟踪父进程；`child`，表示跟踪子进程；`ask`，表示需要用户手动选择跟踪哪个进程。
2. `set scheduler-locking on/off`：开启或关闭调度锁。当调度锁被开启时，gdb 会确保只有一个线程在运行。这样可以更容易地调试多线程程序，但是会影响程序的性能。
3. `thread [thread-id]`：切换到指定的线程或当前运行的线程。
4. `info threads`：列出所有线程的信息，包括线程 ID、状态和当前位置等。
5. `info break`：列出所有断点的信息，包括断点编号、位置和条件等。
6. `thread apply [thread-id-list] [command]`：对指定的线程执行指定的命令。可以使用这个命令同时暂停所有线程、在所有线程中设置断点等。
7. `thread apply all [command]`：对所有线程执行指定的命令。
8. `set schedule-multiple on/off`：开启或关闭多个线程同时运行的模式。当开启多线程模式时，所有线程可以同时运行，这有助于测试程序的并发性。

除了这些命令，gdb 还提供了其他一些命令来帮助调试多线程程序。熟练掌握这些命令可以提高调试效率，减少调试时间。

--ggdb3



next

continue

breakpoint xx



### Docker

run -p <容器名>|<容器ID>

- `-p host_port:docker_port` : 端口映射，将容器的端口映射到宿主机的端口
- `-d` : 默认是 `--detach` 将指定的容器放在后台运行，并且返回一个容器的ID
- `-h` ：默认执行的是`--hostname string` 是用于指定容器的名字
- `-i` ：表示以交互模式运行容器
- `-t` 表示容器启动后会进入其命令行
- `-v` 表示目录映射

#### docker原理

`Docker` 利用 `Linux Namespace` 进行网络、用户、进程等不同资源的隔离，使用 `Linux Cgroups` 技术对资源的使用进行限制与监控，通过 `AUFS` 等存储驱动实现分层结构与增量更新等功能。通过`Union-FS`进行镜像分层存储，极大的提高了利用空间

#### dockerfile关键字

Dockerfile是用于构建Docker镜像的脚本文件，它包含了一系列关键字和指令，用于指定镜像的基础信息、环境变量、依赖包、启动命令等内容。下面是一些Dockerfile的关键字及其含义：

1. FROM：指定基础镜像，Docker镜像是基于其他镜像构建的，FROM指令指定了构建镜像的基础镜像。
2. RUN：用于执行命令，可以安装依赖包、运行脚本等。
3. CMD：指定容器启动时运行的命令，可以通过docker run命令覆盖CMD指定的命令。
4. ENV：指定环境变量，可以在容器内部访问。
5. EXPOSE：指定容器暴露的端口号。
6. ADD/COPY：用于将本地文件或目录复制到容器内部。
7. WORKDIR：指定工作目录，容器启动后会进入该目录。
8. USER：指定运行容器的用户。
9. VOLUME：指定容器挂载的数据卷。
10. ARG：定义构建参数，可以在构建镜像时传递参数。

其中，FROM、RUN、CMD是构建Docker镜像中最重要的几个指令。FROM指定了构建镜像的基础镜像，RUN用于安装依赖包、运行脚本等，CMD指定容器启动时运行的命令，这三个指令是构建Docker镜像的核心内容。其他指令则是用于配置镜像的详细信息、启动参数等。

#### docker compose

在测试目录中创建一个名为 docker-compose.yml 的文件，然后粘贴以下内容：

```yaml
\# yaml 配置
version**:** '3'
services:
 web:
  build**:** .
  ports**:
**   - "5000:5000"
 redis:
  image**:** "redis:alpine"
```

该 Compose 文件定义了两个服务：web 和 redis。

- **web**：该 web 服务使用从 Dockerfile 当前目录中构建的镜像。然后，它将容器和主机绑定到暴露的端口 5000。此示例服务使用 Flask Web 服务器的默认端口 5000 。
- **redis**：该 redis 服务使用 Docker Hub 的公共 Redis 映像。

```yaml
version: '2'

services:
  db:
    image: postgres
    environment:
      - POSTGRES_DB=exchange
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=passw0rd

  serv:
    build: ./src
    user: root
    command: bash -c "cd /code && chmod o+x run.sh && ./run.sh"
    volumes:
      - data-volume:/var/log/erss
      - ./src:/code
    ports:
      - "12345:12345"
    depends_on:
      - db

volumes:
  data-volume:
```

- version：指定使用的 Docker Compose 版本号。
- services：定义各个服务的配置。每个服务都有一个名称，并且可以包含 image、ports、volumes、environment 等配置项。
- image：指定 Docker 映像的名称和标签，用于创建服务的容器。
- ports：指定容器端口与主机之间的映射。
- volumes：指定容器与主机之间的卷挂载。
- environment：指定容器内的环境变量。
- networks：指定容器连接到的网络。
- depends_on：**指定服务依赖的其他服务。可以确保服务按正确的顺序启动。**
- restart：指定容器的重启策略。可以设置为 always、on-failure 等选项。
- build：用于构建自定义映像，指定 Dockerfile 和构建上下文等信息。
- command: 运行某个命令

## 自我介绍

我叫姜志成，我来自杜克大学学校的电子与计算机工程专业的研究生，研究方向是软件工程



- 我想了解一下贵部门方向是什么样子呢？怎么去学习云原生方面知识？

答：基于 `k8s` 做一些组件化的开发、一些应用啊，微服务的引擎这些东西，你可以先去了解一下 `k8s` 是一个基于 `docker` 之上的一个编排系统，这是一个基础

- 有什么相关的项目或者练手的去提升自己呢？

答： 你可以用 `k8s` 的部署命令去玩一下，然后了解一下 `k8s` 的架构，以及容器怎么启动的，这一整套的技术栈，多在虚拟机部署使用

- 云原生对数据库这方面重视吗

答：数据库就是一个可以容器化的一些中间件，比如说像一些 `mysql` 啊，还有一些其他的 `rdies` ，云原生说白了就是一个操作系统

- 你之前是怎么投这个方向的，为什么投这个方向，因为我看相关的经验并没有涉及到这些

答：我想多元化发展

- 云原生的话算法能力没有很高的要求，你的算法已经够了，对于云原生的一些组件、镜像容器这些以及运维报错可以去了解一下

## 语言基础

C++和Java比有什么优缺点



\18. 你大学觉得最有成就感的事情是什么？

\19. 为什么呢？

\20. 你最近在学什么？看了哪些书



\23. 你觉得自己的优点是什么，缺点是什么？

\24. 你对实习的期待是什么样子？

## 场景题





同步机制不是特别会





## 杂

假设 data 是一个列表或字符串，语句 data[6:8] 表示从 data 中取出从索引 6（包含）到索引 8（不包含）之间的元素，返回一个新的列表或字符串。





10  场景题：应该内存相关的优化问题：通过面试官的引导，回答了可以使用B+树来存储，但是面试官说磁盘方面的优化可以做什么，然后说哈希表，以及存的长整型可以怎么处理，答不出来，面试官说的啥有点忘了，是一个可以将数据简短的东西，有懂的可以提示一下吗



Vector和list的区别





声明了一样名字的全局变量和函数内部变量有什么说法

为用户实现一个哈希表，该怎么做，实现哪些接口

几百万个数中找出前100大的数

解析ip地址题目，说思路即可

Post报文的格式





\5. 你觉得困难在哪里，收获了什么

我讲了一下LRU的LinkedHashMap的实现，问了一下实现，问了下具体的实现





\## 计网

\17. TCP的整个流程？



#### 反问